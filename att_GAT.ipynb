{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtRb0OGDrbR6",
        "outputId": "a570533d-a2ef-4349-ea9b-9f330a41a610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.15)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-zdpu5pll\n",
            "  Running command git clone -q https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-zdpu5pll\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==2.1.0) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GATConv\n",
        "from torch_geometric.nn import global_max_pool as gmp\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from math import sqrt\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "VzodFm_hsEkH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class att_GATNet(torch.nn.Module):\n",
        "    def __init__(self, n_features_drug=78, drug_output_dim=128, n_gat_heads = 10, target_length_max = 1000, n_features_target=25, target_embed_dim=128, n_cnn_filters=32, target_kernel = [4,8,12], dropout=0.2):\n",
        "        \n",
        "        super(att_GATNet, self).__init__()\n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        # graph layers\n",
        "        self.gat1 = GATConv(n_features_drug, n_features_drug, heads=n_gat_heads, dropout=dropout)\n",
        "        self.gat2 = GATConv(n_features_drug * n_gat_heads, drug_output_dim, dropout=dropout)\n",
        "        \n",
        "        # Target embeding\n",
        "        self.target_embedding = nn.Embedding(num_embeddings=n_features_target + 1, embedding_dim=target_embed_dim)\n",
        "        \n",
        "        # 1D convolution on protein sequence embeddings\n",
        "        self.Target_CNNs = nn.Sequential(\n",
        "                            nn.Conv1d(in_channels=target_embed_dim, out_channels=n_cnn_filters, kernel_size=target_kernel[0],padding=0),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv1d(in_channels=n_cnn_filters, out_channels=n_cnn_filters*2, kernel_size=target_kernel[1],padding=0),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv1d(in_channels=n_cnn_filters*2, out_channels=n_cnn_filters*4, kernel_size=target_kernel[2],padding=0),\n",
        "                            nn.ReLU(),\n",
        "                            )\n",
        "    \n",
        "        # attention layers\n",
        "        self.drug_attention_layer = nn.Linear(drug_output_dim, drug_output_dim)\n",
        "        self.target_attention_layer = nn.Linear(n_cnn_filters*4, n_cnn_filters*4)\n",
        "        self.attention_layer = nn.Linear(n_cnn_filters*4, n_cnn_filters*4)\n",
        "    \n",
        "        # head prediction MLP\n",
        "        self.target_maxpool = nn.MaxPool1d(kernel_size=target_length_max-target_kernel[0]-target_kernel[1]-target_kernel[2]+3)\n",
        "        self.Head_MLP = nn.Sequential(\n",
        "                        self.dropout,\n",
        "                        nn.Linear(n_cnn_filters*4+drug_output_dim, 1024),\n",
        "                        nn.LeakyReLU(),\n",
        "                        self.dropout,\n",
        "                        nn.Linear(1024, 1024),\n",
        "                        nn.LeakyReLU(),\n",
        "                        self.dropout,\n",
        "                        nn.Linear(1024, 512),\n",
        "                        nn.LeakyReLU(),\n",
        "                        self.dropout,\n",
        "                        nn.Linear(512,1)\n",
        "                        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        \n",
        "        # drug input processed by GATs\n",
        "        x_drug, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x_drug = self.dropout(x_drug)\n",
        "        x_drug = nn.functional.elu(self.gat1(x_drug, edge_index))\n",
        "        x_drug = self.dropout(x_drug)\n",
        "        x_drug = self.relu(self.gat2(x_drug, edge_index))\n",
        "        x_drug, _ = to_dense_batch(x=x_drug, batch=batch)\n",
        "\n",
        "        #print('x_drug:', x_drug.shape)\n",
        "        \n",
        "\n",
        "        # target input processed by CNNs:\n",
        "        x_target = data.target\n",
        "        x_target = self.target_embedding(x_target)\n",
        "        x_target = x_target.permute(0,2,1)\n",
        "        x_target = self.Target_CNNs(x_target)\n",
        "        #print('x_target:',x_target.shape)\n",
        "\n",
        "        # attention layer to concatenate target/drug outputs\n",
        "        drug_att = self.drug_attention_layer(x_drug)\n",
        "        #print('drug_att: ', drug_att.shape)\n",
        "        target_att = self.target_attention_layer(x_target.permute(0, 2, 1))\n",
        "        #print('target_att: ', target_att.shape)\n",
        "        drug_att_layers = torch.unsqueeze(drug_att, 2).repeat(1, 1, x_target.shape[-1], 1)  \n",
        "        target_att_layers = torch.unsqueeze(target_att, 1).repeat(1, x_drug.shape[-2], 1, 1)\n",
        "        #print('drug_att_layers:', drug_att_layers.shape)\n",
        "        #print('target_att_layers:', target_att_layers.shape)\n",
        "        Atten_matrix = self.attention_layer(self.relu(drug_att_layers + target_att_layers))\n",
        "        drug_weight = self.sigmoid(torch.mean(Atten_matrix, 2))\n",
        "        target_weight = self.sigmoid(torch.mean(Atten_matrix, 1).permute(0,2,1))\n",
        "                \n",
        "        # concatenate drug/target outputs with attentions\n",
        "        x_drug= x_drug * 0.5 + x_drug * drug_weight\n",
        "        #print('x_drug: ', x_drug.shape)\n",
        "        x_target = x_target * 0.5 + x_target * target_weight\n",
        "        #print('x_target: ', x_target.shape)\n",
        "        x_drug, _ = torch.max(x_drug, dim=1)\n",
        "        #print('x_drug: ', x_drug.shape)\n",
        "        x_target = self.target_maxpool(x_target).squeeze(2)\n",
        "        #print('x_target: ', x_target.shape)\n",
        "        x = torch.cat([x_drug, x_target], dim=1)\n",
        "        #print('x: ', x.shape)\n",
        "\n",
        "        # head MLP layers to make predictions\n",
        "        y = self.Head_MLP(x)\n",
        "        #print('y', y.shape)\n",
        "        \n",
        "        return y"
      ],
      "metadata": {
        "id": "je9JzK0Xrrw7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 50\n",
        "TEST_BATCH_SIZE = 50\n",
        "LR = 0.0005\n",
        "LOG_INTERVAL = 50\n",
        "NUM_EPOCHS = 100\n",
        "dataset = 'davis'\n",
        "model_st = 'att_GAT'"
      ],
      "metadata": {
        "id": "sgTOduwGs7y_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = InMemoryDataset()\n",
        "data_train.data, data_train.slices = torch.load('drive/MyDrive/dti_model/data/davis_train.pt')\n",
        "train_loader = DataLoader(data_train, batch_size=TEST_BATCH_SIZE, shuffle=True)\n",
        "\n",
        "data_test = InMemoryDataset()\n",
        "data_test.data, data_test.slices = torch.load('drive/MyDrive/dti_model/data/davis_test.pt')\n",
        "test_loader = DataLoader(data_test, batch_size=TEST_BATCH_SIZE, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "UZnF0kvstUP4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training function at each epoch\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
        "    model.train()\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, data.y.view(-1, 1).float().to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train epoch: {} [({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n",
        "                                                                           100. * batch_idx / len(train_loader),\n",
        "                                                                           loss.item()))\n",
        "\n",
        "def predicting(model, device, loader):\n",
        "    model.eval()\n",
        "    total_preds = torch.Tensor()\n",
        "    total_labels = torch.Tensor()\n",
        "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
        "            total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
        "    return total_labels.numpy().flatten(),total_preds.numpy().flatten()\n",
        "\n",
        "\n",
        "def rmse(y,f):\n",
        "    rmse = sqrt(((y - f)**2).mean(axis=0))\n",
        "    return rmse\n",
        "def mse(y,f):\n",
        "    mse = ((y - f)**2).mean(axis=0)\n",
        "    return mse\n",
        "def pearson(y,f):\n",
        "    rp = np.corrcoef(y, f)[0,1]\n",
        "    return rp\n",
        "def spearman(y,f):\n",
        "    rs = stats.spearmanr(y, f)[0]\n",
        "    return rs\n",
        "def ci(y,f):\n",
        "    ind = np.argsort(y)\n",
        "    y = y[ind]\n",
        "    f = f[ind]\n",
        "    i = len(y)-1\n",
        "    j = i-1\n",
        "    z = 0.0\n",
        "    S = 0.0\n",
        "    while i > 0:\n",
        "        while j >= 0:\n",
        "            if y[i] > y[j]:\n",
        "                z = z+1\n",
        "                u = f[i] - f[j]\n",
        "                if u > 0:\n",
        "                    S = S + 1\n",
        "                elif u == 0:\n",
        "                    S = S + 0.5\n",
        "            j = j - 1\n",
        "        i = i - 1\n",
        "        j = i-1\n",
        "    ci = S/z\n",
        "    return ci"
      ],
      "metadata": {
        "id": "Ib7myJBZtXJg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_name = \"cuda:0\"\n",
        "device = torch.device(cuda_name if torch.cuda.is_available() else \"cpu\")\n",
        "model = att_GATNet().to(device)\n",
        "torch.save(model.state_dict(), 'drive/MyDrive/dti_model/checkpoint/model_checkpoint.pt')\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "best_mse = 1000\n",
        "best_ci = 0\n",
        "best_epoch = -1\n",
        "model_file_name = 'drive/MyDrive/dti_model/results/model_' + model_st + '_' + dataset +  '.pt'\n",
        "result_file_name = 'drive/MyDrive/dti_model/results/result_' + model_st + '_' + dataset +  '.csv'\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train(model, device, train_loader, optimizer, epoch+1)\n",
        "    torch.save(model.state_dict(), 'drive/MyDrive/dti_model/checkpoint/model_checkpoint.pt')\n",
        "    G,P = predicting(model, device, test_loader)\n",
        "    ret = [rmse(G,P),mse(G,P),pearson(G,P),spearman(G,P),ci(G,P)]\n",
        "    if ret[1]<best_mse:\n",
        "        torch.save(model.state_dict(), model_file_name)\n",
        "        with open(result_file_name,'w') as f:\n",
        "            f.write(','.join(map(str,ret)))\n",
        "        best_epoch = epoch+1\n",
        "        best_mse = ret[1]\n",
        "        best_ci = ret[-1]\n",
        "        print('rmse improved at epoch ', best_epoch, '; best_mse,best_ci:', best_mse,best_ci,model_st,dataset)\n",
        "    else:\n",
        "        print(ret[1],'No improvement since epoch ', best_epoch, '; best_mse,best_ci:', best_mse,best_ci,model_st,dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w63WJGiLtZFk",
        "outputId": "a8f319fd-30eb-4782-8853-16956a3e58f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 25046 samples...\n",
            "Train epoch: 1 [(0%)]\tLoss: 29.008968\n",
            "Train epoch: 1 [(10%)]\tLoss: 0.904569\n",
            "Train epoch: 1 [(20%)]\tLoss: 0.697856\n",
            "Train epoch: 1 [(30%)]\tLoss: 1.109991\n",
            "Train epoch: 1 [(40%)]\tLoss: 0.596528\n",
            "Train epoch: 1 [(50%)]\tLoss: 0.493935\n",
            "Train epoch: 1 [(60%)]\tLoss: 0.822155\n",
            "Train epoch: 1 [(70%)]\tLoss: 0.584799\n",
            "Train epoch: 1 [(80%)]\tLoss: 1.005527\n",
            "Train epoch: 1 [(90%)]\tLoss: 1.199605\n",
            "Train epoch: 1 [(100%)]\tLoss: 1.350431\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  1 ; best_mse,best_ci: 0.66669285 0.7260917601880592 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 2 [(0%)]\tLoss: 1.104825\n",
            "Train epoch: 2 [(10%)]\tLoss: 0.950154\n",
            "Train epoch: 2 [(20%)]\tLoss: 0.922634\n",
            "Train epoch: 2 [(30%)]\tLoss: 0.909872\n",
            "Train epoch: 2 [(40%)]\tLoss: 0.659156\n",
            "Train epoch: 2 [(50%)]\tLoss: 0.572404\n",
            "Train epoch: 2 [(60%)]\tLoss: 0.621313\n",
            "Train epoch: 2 [(70%)]\tLoss: 0.945201\n",
            "Train epoch: 2 [(80%)]\tLoss: 0.581474\n",
            "Train epoch: 2 [(90%)]\tLoss: 0.506604\n",
            "Train epoch: 2 [(100%)]\tLoss: 0.978318\n",
            "Make prediction for 5010 samples...\n",
            "0.93626714 No improvement since epoch  1 ; best_mse,best_ci: 0.66669285 0.7260917601880592 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 3 [(0%)]\tLoss: 0.736333\n",
            "Train epoch: 3 [(10%)]\tLoss: 0.811391\n",
            "Train epoch: 3 [(20%)]\tLoss: 0.567440\n",
            "Train epoch: 3 [(30%)]\tLoss: 0.991818\n",
            "Train epoch: 3 [(40%)]\tLoss: 0.567072\n",
            "Train epoch: 3 [(50%)]\tLoss: 0.958082\n",
            "Train epoch: 3 [(60%)]\tLoss: 1.200956\n",
            "Train epoch: 3 [(70%)]\tLoss: 0.979069\n",
            "Train epoch: 3 [(80%)]\tLoss: 0.866008\n",
            "Train epoch: 3 [(90%)]\tLoss: 0.588694\n",
            "Train epoch: 3 [(100%)]\tLoss: 0.962227\n",
            "Make prediction for 5010 samples...\n",
            "1.3259116 No improvement since epoch  1 ; best_mse,best_ci: 0.66669285 0.7260917601880592 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 4 [(0%)]\tLoss: 0.800817\n",
            "Train epoch: 4 [(10%)]\tLoss: 0.648398\n",
            "Train epoch: 4 [(20%)]\tLoss: 0.664943\n",
            "Train epoch: 4 [(30%)]\tLoss: 0.522279\n",
            "Train epoch: 4 [(40%)]\tLoss: 0.675194\n",
            "Train epoch: 4 [(50%)]\tLoss: 0.410161\n",
            "Train epoch: 4 [(60%)]\tLoss: 0.560637\n",
            "Train epoch: 4 [(70%)]\tLoss: 1.157055\n",
            "Train epoch: 4 [(80%)]\tLoss: 0.707936\n",
            "Train epoch: 4 [(90%)]\tLoss: 0.732524\n",
            "Train epoch: 4 [(100%)]\tLoss: 0.829367\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  4 ; best_mse,best_ci: 0.65094954 0.7584716008265955 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 5 [(0%)]\tLoss: 0.489870\n",
            "Train epoch: 5 [(10%)]\tLoss: 0.402637\n",
            "Train epoch: 5 [(20%)]\tLoss: 0.802908\n",
            "Train epoch: 5 [(30%)]\tLoss: 0.724326\n",
            "Train epoch: 5 [(40%)]\tLoss: 0.776130\n",
            "Train epoch: 5 [(50%)]\tLoss: 0.692025\n",
            "Train epoch: 5 [(60%)]\tLoss: 1.777986\n",
            "Train epoch: 5 [(70%)]\tLoss: 0.494395\n",
            "Train epoch: 5 [(80%)]\tLoss: 0.420844\n",
            "Train epoch: 5 [(90%)]\tLoss: 0.754940\n",
            "Train epoch: 5 [(100%)]\tLoss: 1.181014\n",
            "Make prediction for 5010 samples...\n",
            "0.7545202 No improvement since epoch  4 ; best_mse,best_ci: 0.65094954 0.7584716008265955 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 6 [(0%)]\tLoss: 0.657081\n",
            "Train epoch: 6 [(10%)]\tLoss: 0.991552\n",
            "Train epoch: 6 [(20%)]\tLoss: 0.892302\n",
            "Train epoch: 6 [(30%)]\tLoss: 0.982796\n",
            "Train epoch: 6 [(40%)]\tLoss: 0.855694\n",
            "Train epoch: 6 [(50%)]\tLoss: 1.125038\n",
            "Train epoch: 6 [(60%)]\tLoss: 0.579089\n",
            "Train epoch: 6 [(70%)]\tLoss: 0.795401\n",
            "Train epoch: 6 [(80%)]\tLoss: 0.753612\n",
            "Train epoch: 6 [(90%)]\tLoss: 0.659998\n",
            "Train epoch: 6 [(100%)]\tLoss: 0.981579\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  6 ; best_mse,best_ci: 0.6431258 0.7546829104456696 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 7 [(0%)]\tLoss: 0.696803\n",
            "Train epoch: 7 [(10%)]\tLoss: 0.647796\n",
            "Train epoch: 7 [(20%)]\tLoss: 0.316574\n",
            "Train epoch: 7 [(30%)]\tLoss: 0.629411\n",
            "Train epoch: 7 [(40%)]\tLoss: 0.489797\n",
            "Train epoch: 7 [(50%)]\tLoss: 0.463561\n",
            "Train epoch: 7 [(60%)]\tLoss: 0.824669\n",
            "Train epoch: 7 [(70%)]\tLoss: 0.393562\n",
            "Train epoch: 7 [(80%)]\tLoss: 0.426324\n",
            "Train epoch: 7 [(90%)]\tLoss: 0.706182\n",
            "Train epoch: 7 [(100%)]\tLoss: 0.886398\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  7 ; best_mse,best_ci: 0.5949888 0.7594402147935356 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 8 [(0%)]\tLoss: 0.835854\n",
            "Train epoch: 8 [(10%)]\tLoss: 0.473161\n",
            "Train epoch: 8 [(20%)]\tLoss: 0.802384\n",
            "Train epoch: 8 [(30%)]\tLoss: 0.603582\n",
            "Train epoch: 8 [(40%)]\tLoss: 0.268158\n",
            "Train epoch: 8 [(50%)]\tLoss: 0.583094\n",
            "Train epoch: 8 [(60%)]\tLoss: 1.071282\n",
            "Train epoch: 8 [(70%)]\tLoss: 0.631084\n",
            "Train epoch: 8 [(80%)]\tLoss: 0.478319\n",
            "Train epoch: 8 [(90%)]\tLoss: 0.560435\n",
            "Train epoch: 8 [(100%)]\tLoss: 0.737416\n",
            "Make prediction for 5010 samples...\n",
            "0.5977651 No improvement since epoch  7 ; best_mse,best_ci: 0.5949888 0.7594402147935356 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 9 [(0%)]\tLoss: 0.367453\n",
            "Train epoch: 9 [(10%)]\tLoss: 0.879278\n",
            "Train epoch: 9 [(20%)]\tLoss: 0.455653\n",
            "Train epoch: 9 [(30%)]\tLoss: 0.529047\n",
            "Train epoch: 9 [(40%)]\tLoss: 0.676326\n",
            "Train epoch: 9 [(50%)]\tLoss: 0.747370\n",
            "Train epoch: 9 [(60%)]\tLoss: 0.476295\n",
            "Train epoch: 9 [(70%)]\tLoss: 0.739765\n",
            "Train epoch: 9 [(80%)]\tLoss: 1.566239\n",
            "Train epoch: 9 [(90%)]\tLoss: 0.671684\n",
            "Train epoch: 9 [(100%)]\tLoss: 0.613169\n",
            "Make prediction for 5010 samples...\n",
            "0.6366823 No improvement since epoch  7 ; best_mse,best_ci: 0.5949888 0.7594402147935356 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 10 [(0%)]\tLoss: 0.567113\n",
            "Train epoch: 10 [(10%)]\tLoss: 0.913751\n",
            "Train epoch: 10 [(20%)]\tLoss: 0.669940\n",
            "Train epoch: 10 [(30%)]\tLoss: 0.485171\n",
            "Train epoch: 10 [(40%)]\tLoss: 0.281239\n",
            "Train epoch: 10 [(50%)]\tLoss: 0.369466\n",
            "Train epoch: 10 [(60%)]\tLoss: 0.471176\n",
            "Train epoch: 10 [(70%)]\tLoss: 0.718023\n",
            "Train epoch: 10 [(80%)]\tLoss: 0.519710\n",
            "Train epoch: 10 [(90%)]\tLoss: 0.244830\n",
            "Train epoch: 10 [(100%)]\tLoss: 0.740494\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  10 ; best_mse,best_ci: 0.58223706 0.7718821833381244 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 11 [(0%)]\tLoss: 0.522438\n",
            "Train epoch: 11 [(10%)]\tLoss: 0.484077\n",
            "Train epoch: 11 [(20%)]\tLoss: 0.841094\n",
            "Train epoch: 11 [(30%)]\tLoss: 0.710283\n",
            "Train epoch: 11 [(40%)]\tLoss: 0.821496\n",
            "Train epoch: 11 [(50%)]\tLoss: 0.459240\n",
            "Train epoch: 11 [(60%)]\tLoss: 0.772793\n",
            "Train epoch: 11 [(70%)]\tLoss: 0.769468\n",
            "Train epoch: 11 [(80%)]\tLoss: 0.630249\n",
            "Train epoch: 11 [(90%)]\tLoss: 0.627526\n",
            "Train epoch: 11 [(100%)]\tLoss: 0.403815\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  11 ; best_mse,best_ci: 0.54945755 0.7956234484678838 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 12 [(0%)]\tLoss: 0.716060\n",
            "Train epoch: 12 [(10%)]\tLoss: 0.519023\n",
            "Train epoch: 12 [(20%)]\tLoss: 0.542661\n",
            "Train epoch: 12 [(30%)]\tLoss: 0.406392\n",
            "Train epoch: 12 [(40%)]\tLoss: 0.619450\n",
            "Train epoch: 12 [(50%)]\tLoss: 0.394193\n",
            "Train epoch: 12 [(60%)]\tLoss: 0.590369\n",
            "Train epoch: 12 [(70%)]\tLoss: 0.432152\n",
            "Train epoch: 12 [(80%)]\tLoss: 0.850610\n",
            "Train epoch: 12 [(90%)]\tLoss: 0.483884\n",
            "Train epoch: 12 [(100%)]\tLoss: 1.300064\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  12 ; best_mse,best_ci: 0.5116606 0.7914699484626 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 13 [(0%)]\tLoss: 0.548301\n",
            "Train epoch: 13 [(10%)]\tLoss: 0.645596\n",
            "Train epoch: 13 [(20%)]\tLoss: 0.517401\n",
            "Train epoch: 13 [(30%)]\tLoss: 0.364029\n",
            "Train epoch: 13 [(40%)]\tLoss: 0.420784\n",
            "Train epoch: 13 [(50%)]\tLoss: 1.162005\n",
            "Train epoch: 13 [(60%)]\tLoss: 0.546342\n",
            "Train epoch: 13 [(70%)]\tLoss: 0.317800\n",
            "Train epoch: 13 [(80%)]\tLoss: 0.650316\n",
            "Train epoch: 13 [(90%)]\tLoss: 0.496441\n",
            "Train epoch: 13 [(100%)]\tLoss: 0.384153\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  13 ; best_mse,best_ci: 0.5086604 0.8027349388530367 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 14 [(0%)]\tLoss: 0.442935\n",
            "Train epoch: 14 [(10%)]\tLoss: 0.447277\n",
            "Train epoch: 14 [(20%)]\tLoss: 0.290821\n",
            "Train epoch: 14 [(30%)]\tLoss: 0.490496\n",
            "Train epoch: 14 [(40%)]\tLoss: 0.673102\n",
            "Train epoch: 14 [(50%)]\tLoss: 0.542543\n",
            "Train epoch: 14 [(60%)]\tLoss: 0.192541\n",
            "Train epoch: 14 [(70%)]\tLoss: 0.432131\n",
            "Train epoch: 14 [(80%)]\tLoss: 0.585966\n",
            "Train epoch: 14 [(90%)]\tLoss: 0.383450\n",
            "Train epoch: 14 [(100%)]\tLoss: 0.508702\n",
            "Make prediction for 5010 samples...\n",
            "0.5169645 No improvement since epoch  13 ; best_mse,best_ci: 0.5086604 0.8027349388530367 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 15 [(0%)]\tLoss: 0.691394\n",
            "Train epoch: 15 [(10%)]\tLoss: 0.237161\n",
            "Train epoch: 15 [(20%)]\tLoss: 0.402519\n",
            "Train epoch: 15 [(30%)]\tLoss: 0.334945\n",
            "Train epoch: 15 [(40%)]\tLoss: 0.223771\n",
            "Train epoch: 15 [(50%)]\tLoss: 0.256672\n",
            "Train epoch: 15 [(60%)]\tLoss: 0.421387\n",
            "Train epoch: 15 [(70%)]\tLoss: 0.452675\n",
            "Train epoch: 15 [(80%)]\tLoss: 0.483063\n",
            "Train epoch: 15 [(90%)]\tLoss: 0.378507\n",
            "Train epoch: 15 [(100%)]\tLoss: 0.545978\n",
            "Make prediction for 5010 samples...\n",
            "0.52102745 No improvement since epoch  13 ; best_mse,best_ci: 0.5086604 0.8027349388530367 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 16 [(0%)]\tLoss: 0.285819\n",
            "Train epoch: 16 [(10%)]\tLoss: 0.486421\n",
            "Train epoch: 16 [(20%)]\tLoss: 0.698594\n",
            "Train epoch: 16 [(30%)]\tLoss: 0.484501\n",
            "Train epoch: 16 [(40%)]\tLoss: 0.300055\n",
            "Train epoch: 16 [(50%)]\tLoss: 0.880274\n",
            "Train epoch: 16 [(60%)]\tLoss: 1.460198\n",
            "Train epoch: 16 [(70%)]\tLoss: 0.661910\n",
            "Train epoch: 16 [(80%)]\tLoss: 0.656378\n",
            "Train epoch: 16 [(90%)]\tLoss: 0.410833\n",
            "Train epoch: 16 [(100%)]\tLoss: 0.385081\n",
            "Make prediction for 5010 samples...\n",
            "0.509593 No improvement since epoch  13 ; best_mse,best_ci: 0.5086604 0.8027349388530367 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 17 [(0%)]\tLoss: 0.807470\n",
            "Train epoch: 17 [(10%)]\tLoss: 0.444845\n",
            "Train epoch: 17 [(20%)]\tLoss: 0.279034\n",
            "Train epoch: 17 [(30%)]\tLoss: 0.488648\n",
            "Train epoch: 17 [(40%)]\tLoss: 0.541372\n",
            "Train epoch: 17 [(50%)]\tLoss: 0.486595\n",
            "Train epoch: 17 [(60%)]\tLoss: 0.259275\n",
            "Train epoch: 17 [(70%)]\tLoss: 0.376672\n",
            "Train epoch: 17 [(80%)]\tLoss: 0.738512\n",
            "Train epoch: 17 [(90%)]\tLoss: 0.583309\n",
            "Train epoch: 17 [(100%)]\tLoss: 0.455404\n",
            "Make prediction for 5010 samples...\n",
            "0.5407254 No improvement since epoch  13 ; best_mse,best_ci: 0.5086604 0.8027349388530367 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 18 [(0%)]\tLoss: 0.370004\n",
            "Train epoch: 18 [(10%)]\tLoss: 0.419389\n",
            "Train epoch: 18 [(20%)]\tLoss: 0.445872\n",
            "Train epoch: 18 [(30%)]\tLoss: 0.520528\n",
            "Train epoch: 18 [(40%)]\tLoss: 0.678354\n",
            "Train epoch: 18 [(50%)]\tLoss: 0.345899\n",
            "Train epoch: 18 [(60%)]\tLoss: 0.689943\n",
            "Train epoch: 18 [(70%)]\tLoss: 0.951767\n",
            "Train epoch: 18 [(80%)]\tLoss: 0.590737\n",
            "Train epoch: 18 [(90%)]\tLoss: 0.349883\n",
            "Train epoch: 18 [(100%)]\tLoss: 0.390281\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  18 ; best_mse,best_ci: 0.48782006 0.819731820511827 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 19 [(0%)]\tLoss: 0.241515\n",
            "Train epoch: 19 [(10%)]\tLoss: 0.263088\n",
            "Train epoch: 19 [(20%)]\tLoss: 0.459183\n",
            "Train epoch: 19 [(30%)]\tLoss: 0.719549\n",
            "Train epoch: 19 [(40%)]\tLoss: 0.573920\n",
            "Train epoch: 19 [(50%)]\tLoss: 0.998966\n",
            "Train epoch: 19 [(60%)]\tLoss: 0.300104\n",
            "Train epoch: 19 [(70%)]\tLoss: 0.344198\n",
            "Train epoch: 19 [(80%)]\tLoss: 0.709212\n",
            "Train epoch: 19 [(90%)]\tLoss: 0.512696\n",
            "Train epoch: 19 [(100%)]\tLoss: 0.402116\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  19 ; best_mse,best_ci: 0.44742367 0.831873456699839 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 20 [(0%)]\tLoss: 0.319461\n",
            "Train epoch: 20 [(10%)]\tLoss: 0.396072\n",
            "Train epoch: 20 [(20%)]\tLoss: 0.272428\n",
            "Train epoch: 20 [(30%)]\tLoss: 0.763714\n",
            "Train epoch: 20 [(40%)]\tLoss: 0.286118\n",
            "Train epoch: 20 [(50%)]\tLoss: 0.539918\n",
            "Train epoch: 20 [(60%)]\tLoss: 0.442776\n",
            "Train epoch: 20 [(70%)]\tLoss: 0.513985\n",
            "Train epoch: 20 [(80%)]\tLoss: 0.637344\n",
            "Train epoch: 20 [(90%)]\tLoss: 0.316725\n",
            "Train epoch: 20 [(100%)]\tLoss: 0.420669\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  20 ; best_mse,best_ci: 0.44725227 0.8290198398543948 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 21 [(0%)]\tLoss: 0.757635\n",
            "Train epoch: 21 [(10%)]\tLoss: 0.530361\n",
            "Train epoch: 21 [(20%)]\tLoss: 0.568259\n",
            "Train epoch: 21 [(30%)]\tLoss: 0.237179\n",
            "Train epoch: 21 [(40%)]\tLoss: 0.345702\n",
            "Train epoch: 21 [(50%)]\tLoss: 0.620460\n",
            "Train epoch: 21 [(60%)]\tLoss: 0.986073\n",
            "Train epoch: 21 [(70%)]\tLoss: 0.353506\n",
            "Train epoch: 21 [(80%)]\tLoss: 0.265372\n",
            "Train epoch: 21 [(90%)]\tLoss: 0.407470\n",
            "Train epoch: 21 [(100%)]\tLoss: 0.505058\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  21 ; best_mse,best_ci: 0.43149415 0.8410899537524927 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 22 [(0%)]\tLoss: 0.396015\n",
            "Train epoch: 22 [(10%)]\tLoss: 0.614632\n",
            "Train epoch: 22 [(20%)]\tLoss: 0.455965\n",
            "Train epoch: 22 [(30%)]\tLoss: 0.460192\n",
            "Train epoch: 22 [(40%)]\tLoss: 0.398883\n",
            "Train epoch: 22 [(50%)]\tLoss: 0.652111\n",
            "Train epoch: 22 [(60%)]\tLoss: 0.440875\n",
            "Train epoch: 22 [(70%)]\tLoss: 0.222936\n",
            "Train epoch: 22 [(80%)]\tLoss: 0.379293\n",
            "Train epoch: 22 [(90%)]\tLoss: 0.282823\n",
            "Train epoch: 22 [(100%)]\tLoss: 0.209759\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  22 ; best_mse,best_ci: 0.41798094 0.8439098770138234 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 23 [(0%)]\tLoss: 0.184748\n",
            "Train epoch: 23 [(10%)]\tLoss: 0.496839\n",
            "Train epoch: 23 [(20%)]\tLoss: 0.556033\n",
            "Train epoch: 23 [(30%)]\tLoss: 0.431346\n",
            "Train epoch: 23 [(40%)]\tLoss: 0.219372\n",
            "Train epoch: 23 [(50%)]\tLoss: 0.449175\n",
            "Train epoch: 23 [(60%)]\tLoss: 0.394710\n",
            "Train epoch: 23 [(70%)]\tLoss: 0.569552\n",
            "Train epoch: 23 [(80%)]\tLoss: 0.216547\n",
            "Train epoch: 23 [(90%)]\tLoss: 0.393173\n",
            "Train epoch: 23 [(100%)]\tLoss: 0.498051\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  23 ; best_mse,best_ci: 0.39064658 0.8457898258547105 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 24 [(0%)]\tLoss: 0.528001\n",
            "Train epoch: 24 [(10%)]\tLoss: 0.242614\n",
            "Train epoch: 24 [(20%)]\tLoss: 0.256350\n",
            "Train epoch: 24 [(30%)]\tLoss: 0.359033\n",
            "Train epoch: 24 [(40%)]\tLoss: 0.442612\n",
            "Train epoch: 24 [(50%)]\tLoss: 0.440254\n",
            "Train epoch: 24 [(60%)]\tLoss: 0.525460\n",
            "Train epoch: 24 [(70%)]\tLoss: 0.726965\n",
            "Train epoch: 24 [(80%)]\tLoss: 0.459007\n",
            "Train epoch: 24 [(90%)]\tLoss: 0.367366\n",
            "Train epoch: 24 [(100%)]\tLoss: 0.373577\n",
            "Make prediction for 5010 samples...\n",
            "0.39487657 No improvement since epoch  23 ; best_mse,best_ci: 0.39064658 0.8457898258547105 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 25 [(0%)]\tLoss: 0.257086\n",
            "Train epoch: 25 [(10%)]\tLoss: 0.434895\n",
            "Train epoch: 25 [(20%)]\tLoss: 0.357031\n",
            "Train epoch: 25 [(30%)]\tLoss: 0.580842\n",
            "Train epoch: 25 [(40%)]\tLoss: 0.130706\n",
            "Train epoch: 25 [(50%)]\tLoss: 0.525282\n",
            "Train epoch: 25 [(60%)]\tLoss: 0.381511\n",
            "Train epoch: 25 [(70%)]\tLoss: 0.342100\n",
            "Train epoch: 25 [(80%)]\tLoss: 0.273071\n",
            "Train epoch: 25 [(90%)]\tLoss: 0.423668\n",
            "Train epoch: 25 [(100%)]\tLoss: 0.478470\n",
            "Make prediction for 5010 samples...\n",
            "0.40762088 No improvement since epoch  23 ; best_mse,best_ci: 0.39064658 0.8457898258547105 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 26 [(0%)]\tLoss: 0.162755\n",
            "Train epoch: 26 [(10%)]\tLoss: 0.308159\n",
            "Train epoch: 26 [(20%)]\tLoss: 0.309157\n",
            "Train epoch: 26 [(30%)]\tLoss: 0.431145\n",
            "Train epoch: 26 [(40%)]\tLoss: 0.316128\n",
            "Train epoch: 26 [(50%)]\tLoss: 0.348408\n",
            "Train epoch: 26 [(60%)]\tLoss: 0.167204\n",
            "Train epoch: 26 [(70%)]\tLoss: 0.386432\n",
            "Train epoch: 26 [(80%)]\tLoss: 0.450018\n",
            "Train epoch: 26 [(90%)]\tLoss: 0.475758\n",
            "Train epoch: 26 [(100%)]\tLoss: 0.474970\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  26 ; best_mse,best_ci: 0.377405 0.8571904329212047 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 27 [(0%)]\tLoss: 0.359796\n",
            "Train epoch: 27 [(10%)]\tLoss: 0.257838\n",
            "Train epoch: 27 [(20%)]\tLoss: 0.291918\n",
            "Train epoch: 27 [(30%)]\tLoss: 0.413611\n",
            "Train epoch: 27 [(40%)]\tLoss: 0.290774\n",
            "Train epoch: 27 [(50%)]\tLoss: 0.155352\n",
            "Train epoch: 27 [(60%)]\tLoss: 0.269869\n",
            "Train epoch: 27 [(70%)]\tLoss: 0.272800\n",
            "Train epoch: 27 [(80%)]\tLoss: 0.236423\n",
            "Train epoch: 27 [(90%)]\tLoss: 0.261304\n",
            "Train epoch: 27 [(100%)]\tLoss: 0.781005\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  27 ; best_mse,best_ci: 0.37696216 0.8527849967983437 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 28 [(0%)]\tLoss: 0.245048\n",
            "Train epoch: 28 [(10%)]\tLoss: 0.378617\n",
            "Train epoch: 28 [(20%)]\tLoss: 0.179604\n",
            "Train epoch: 28 [(30%)]\tLoss: 0.591247\n",
            "Train epoch: 28 [(40%)]\tLoss: 0.542366\n",
            "Train epoch: 28 [(50%)]\tLoss: 0.423569\n",
            "Train epoch: 28 [(60%)]\tLoss: 0.277195\n",
            "Train epoch: 28 [(70%)]\tLoss: 0.387115\n",
            "Train epoch: 28 [(80%)]\tLoss: 0.857290\n",
            "Train epoch: 28 [(90%)]\tLoss: 0.394050\n",
            "Train epoch: 28 [(100%)]\tLoss: 0.386174\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  28 ; best_mse,best_ci: 0.34219003 0.8607349213936341 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 29 [(0%)]\tLoss: 0.557954\n",
            "Train epoch: 29 [(10%)]\tLoss: 0.228427\n",
            "Train epoch: 29 [(20%)]\tLoss: 0.323184\n",
            "Train epoch: 29 [(30%)]\tLoss: 0.387410\n",
            "Train epoch: 29 [(40%)]\tLoss: 0.202675\n",
            "Train epoch: 29 [(50%)]\tLoss: 0.338755\n",
            "Train epoch: 29 [(60%)]\tLoss: 0.239707\n",
            "Train epoch: 29 [(70%)]\tLoss: 0.437957\n",
            "Train epoch: 29 [(80%)]\tLoss: 0.408635\n",
            "Train epoch: 29 [(90%)]\tLoss: 0.546247\n",
            "Train epoch: 29 [(100%)]\tLoss: 0.205248\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  29 ; best_mse,best_ci: 0.33822584 0.8662681736683722 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 30 [(0%)]\tLoss: 0.760359\n",
            "Train epoch: 30 [(10%)]\tLoss: 0.272998\n",
            "Train epoch: 30 [(20%)]\tLoss: 0.304986\n",
            "Train epoch: 30 [(30%)]\tLoss: 0.357951\n",
            "Train epoch: 30 [(40%)]\tLoss: 0.483689\n",
            "Train epoch: 30 [(50%)]\tLoss: 0.597695\n",
            "Train epoch: 30 [(60%)]\tLoss: 0.435115\n",
            "Train epoch: 30 [(70%)]\tLoss: 0.323766\n",
            "Train epoch: 30 [(80%)]\tLoss: 0.290483\n",
            "Train epoch: 30 [(90%)]\tLoss: 0.483250\n",
            "Train epoch: 30 [(100%)]\tLoss: 0.368045\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  30 ; best_mse,best_ci: 0.33129147 0.8635229123263842 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 31 [(0%)]\tLoss: 0.380990\n",
            "Train epoch: 31 [(10%)]\tLoss: 0.389549\n",
            "Train epoch: 31 [(20%)]\tLoss: 0.342165\n",
            "Train epoch: 31 [(30%)]\tLoss: 0.297614\n",
            "Train epoch: 31 [(40%)]\tLoss: 0.336547\n",
            "Train epoch: 31 [(50%)]\tLoss: 0.207320\n",
            "Train epoch: 31 [(60%)]\tLoss: 0.872685\n",
            "Train epoch: 31 [(70%)]\tLoss: 0.416864\n",
            "Train epoch: 31 [(80%)]\tLoss: 0.410953\n",
            "Train epoch: 31 [(90%)]\tLoss: 0.382445\n",
            "Train epoch: 31 [(100%)]\tLoss: 0.572599\n",
            "Make prediction for 5010 samples...\n",
            "0.37793383 No improvement since epoch  30 ; best_mse,best_ci: 0.33129147 0.8635229123263842 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 32 [(0%)]\tLoss: 0.210296\n",
            "Train epoch: 32 [(10%)]\tLoss: 0.145830\n",
            "Train epoch: 32 [(20%)]\tLoss: 0.195648\n",
            "Train epoch: 32 [(30%)]\tLoss: 0.317682\n",
            "Train epoch: 32 [(40%)]\tLoss: 0.207502\n",
            "Train epoch: 32 [(50%)]\tLoss: 0.214446\n",
            "Train epoch: 32 [(60%)]\tLoss: 0.299763\n",
            "Train epoch: 32 [(70%)]\tLoss: 0.338087\n",
            "Train epoch: 32 [(80%)]\tLoss: 0.382117\n",
            "Train epoch: 32 [(90%)]\tLoss: 0.392306\n",
            "Train epoch: 32 [(100%)]\tLoss: 0.297324\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  32 ; best_mse,best_ci: 0.31729153 0.8695184558904272 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 33 [(0%)]\tLoss: 0.174663\n",
            "Train epoch: 33 [(10%)]\tLoss: 0.468595\n",
            "Train epoch: 33 [(20%)]\tLoss: 0.191692\n",
            "Train epoch: 33 [(30%)]\tLoss: 0.195858\n",
            "Train epoch: 33 [(40%)]\tLoss: 0.668455\n",
            "Train epoch: 33 [(50%)]\tLoss: 0.342972\n",
            "Train epoch: 33 [(60%)]\tLoss: 0.182127\n",
            "Train epoch: 33 [(70%)]\tLoss: 0.216224\n",
            "Train epoch: 33 [(80%)]\tLoss: 0.298280\n",
            "Train epoch: 33 [(90%)]\tLoss: 0.428336\n",
            "Train epoch: 33 [(100%)]\tLoss: 0.411651\n",
            "Make prediction for 5010 samples...\n",
            "0.3550565 No improvement since epoch  32 ; best_mse,best_ci: 0.31729153 0.8695184558904272 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 34 [(0%)]\tLoss: 0.440622\n",
            "Train epoch: 34 [(10%)]\tLoss: 0.314579\n",
            "Train epoch: 34 [(20%)]\tLoss: 0.406876\n",
            "Train epoch: 34 [(30%)]\tLoss: 0.407046\n",
            "Train epoch: 34 [(40%)]\tLoss: 0.617381\n",
            "Train epoch: 34 [(50%)]\tLoss: 0.218255\n",
            "Train epoch: 34 [(60%)]\tLoss: 0.351425\n",
            "Train epoch: 34 [(70%)]\tLoss: 0.263691\n",
            "Train epoch: 34 [(80%)]\tLoss: 0.201783\n",
            "Train epoch: 34 [(90%)]\tLoss: 0.426126\n",
            "Train epoch: 34 [(100%)]\tLoss: 0.338814\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 35 [(0%)]\tLoss: 0.272908\n",
            "Train epoch: 35 [(10%)]\tLoss: 0.268309\n",
            "Train epoch: 35 [(20%)]\tLoss: 0.408058\n",
            "Train epoch: 35 [(30%)]\tLoss: 0.590197\n",
            "Train epoch: 35 [(40%)]\tLoss: 0.290961\n",
            "Train epoch: 35 [(50%)]\tLoss: 0.285364\n",
            "Train epoch: 35 [(60%)]\tLoss: 0.350684\n",
            "Train epoch: 35 [(70%)]\tLoss: 0.766913\n",
            "Train epoch: 35 [(80%)]\tLoss: 0.304479\n",
            "Train epoch: 35 [(90%)]\tLoss: 0.840519\n",
            "Train epoch: 35 [(100%)]\tLoss: 0.626662\n",
            "Make prediction for 5010 samples...\n",
            "0.44430885 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 36 [(0%)]\tLoss: 0.368744\n",
            "Train epoch: 36 [(10%)]\tLoss: 0.663212\n",
            "Train epoch: 36 [(20%)]\tLoss: 0.593744\n",
            "Train epoch: 36 [(30%)]\tLoss: 0.350318\n",
            "Train epoch: 36 [(40%)]\tLoss: 0.272491\n",
            "Train epoch: 36 [(50%)]\tLoss: 0.240982\n",
            "Train epoch: 36 [(60%)]\tLoss: 0.305260\n",
            "Train epoch: 36 [(70%)]\tLoss: 0.375725\n",
            "Train epoch: 36 [(80%)]\tLoss: 0.260056\n",
            "Train epoch: 36 [(90%)]\tLoss: 0.287606\n",
            "Train epoch: 36 [(100%)]\tLoss: 0.490744\n",
            "Make prediction for 5010 samples...\n",
            "0.35062876 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 37 [(0%)]\tLoss: 0.389818\n",
            "Train epoch: 37 [(10%)]\tLoss: 0.408603\n",
            "Train epoch: 37 [(20%)]\tLoss: 0.316669\n",
            "Train epoch: 37 [(30%)]\tLoss: 0.198747\n",
            "Train epoch: 37 [(40%)]\tLoss: 0.465255\n",
            "Train epoch: 37 [(50%)]\tLoss: 0.275411\n",
            "Train epoch: 37 [(60%)]\tLoss: 0.458904\n",
            "Train epoch: 37 [(70%)]\tLoss: 0.470408\n",
            "Train epoch: 37 [(80%)]\tLoss: 0.442468\n",
            "Train epoch: 37 [(90%)]\tLoss: 0.398797\n",
            "Train epoch: 37 [(100%)]\tLoss: 0.172037\n",
            "Make prediction for 5010 samples...\n",
            "0.31311503 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 38 [(0%)]\tLoss: 0.273845\n",
            "Train epoch: 38 [(10%)]\tLoss: 0.246450\n",
            "Train epoch: 38 [(20%)]\tLoss: 0.231761\n",
            "Train epoch: 38 [(30%)]\tLoss: 0.355396\n",
            "Train epoch: 38 [(40%)]\tLoss: 0.510194\n",
            "Train epoch: 38 [(50%)]\tLoss: 0.321423\n",
            "Train epoch: 38 [(60%)]\tLoss: 0.511309\n",
            "Train epoch: 38 [(70%)]\tLoss: 0.396534\n",
            "Train epoch: 38 [(80%)]\tLoss: 0.417591\n",
            "Train epoch: 38 [(90%)]\tLoss: 0.430553\n",
            "Train epoch: 38 [(100%)]\tLoss: 0.383085\n",
            "Make prediction for 5010 samples...\n",
            "0.31538075 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 39 [(0%)]\tLoss: 0.313651\n",
            "Train epoch: 39 [(10%)]\tLoss: 0.562036\n",
            "Train epoch: 39 [(20%)]\tLoss: 0.571097\n",
            "Train epoch: 39 [(30%)]\tLoss: 0.201928\n",
            "Train epoch: 39 [(40%)]\tLoss: 0.624157\n",
            "Train epoch: 39 [(50%)]\tLoss: 0.365712\n",
            "Train epoch: 39 [(60%)]\tLoss: 0.427059\n",
            "Train epoch: 39 [(70%)]\tLoss: 0.243209\n",
            "Train epoch: 39 [(80%)]\tLoss: 0.299204\n",
            "Train epoch: 39 [(90%)]\tLoss: 0.684691\n",
            "Train epoch: 39 [(100%)]\tLoss: 0.222992\n",
            "Make prediction for 5010 samples...\n",
            "0.32465577 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 40 [(0%)]\tLoss: 0.166134\n",
            "Train epoch: 40 [(10%)]\tLoss: 0.304316\n",
            "Train epoch: 40 [(20%)]\tLoss: 0.402957\n",
            "Train epoch: 40 [(30%)]\tLoss: 0.249225\n",
            "Train epoch: 40 [(40%)]\tLoss: 0.285963\n",
            "Train epoch: 40 [(50%)]\tLoss: 0.324304\n",
            "Train epoch: 40 [(60%)]\tLoss: 0.277543\n",
            "Train epoch: 40 [(70%)]\tLoss: 0.320072\n",
            "Train epoch: 40 [(80%)]\tLoss: 0.192162\n",
            "Train epoch: 40 [(90%)]\tLoss: 0.490184\n",
            "Train epoch: 40 [(100%)]\tLoss: 0.490997\n",
            "Make prediction for 5010 samples...\n",
            "0.3231083 No improvement since epoch  34 ; best_mse,best_ci: 0.31086987 0.8705273490056488 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 41 [(0%)]\tLoss: 0.392000\n",
            "Train epoch: 41 [(10%)]\tLoss: 0.363368\n",
            "Train epoch: 41 [(20%)]\tLoss: 0.377846\n",
            "Train epoch: 41 [(30%)]\tLoss: 0.557057\n",
            "Train epoch: 41 [(40%)]\tLoss: 0.357302\n",
            "Train epoch: 41 [(50%)]\tLoss: 0.650976\n",
            "Train epoch: 41 [(60%)]\tLoss: 0.401872\n",
            "Train epoch: 41 [(70%)]\tLoss: 0.349795\n",
            "Train epoch: 41 [(80%)]\tLoss: 0.272489\n",
            "Train epoch: 41 [(90%)]\tLoss: 0.201413\n",
            "Train epoch: 41 [(100%)]\tLoss: 0.193293\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  41 ; best_mse,best_ci: 0.27766466 0.8791454786349749 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 42 [(0%)]\tLoss: 0.346281\n",
            "Train epoch: 42 [(10%)]\tLoss: 0.159752\n",
            "Train epoch: 42 [(20%)]\tLoss: 0.276267\n",
            "Train epoch: 42 [(30%)]\tLoss: 0.135810\n",
            "Train epoch: 42 [(40%)]\tLoss: 0.257379\n",
            "Train epoch: 42 [(50%)]\tLoss: 0.233195\n",
            "Train epoch: 42 [(60%)]\tLoss: 0.299620\n",
            "Train epoch: 42 [(70%)]\tLoss: 0.359588\n",
            "Train epoch: 42 [(80%)]\tLoss: 0.260206\n",
            "Train epoch: 42 [(90%)]\tLoss: 0.279756\n",
            "Train epoch: 42 [(100%)]\tLoss: 0.472487\n",
            "Make prediction for 5010 samples...\n",
            "0.29317454 No improvement since epoch  41 ; best_mse,best_ci: 0.27766466 0.8791454786349749 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 43 [(0%)]\tLoss: 0.296622\n",
            "Train epoch: 43 [(10%)]\tLoss: 0.120835\n",
            "Train epoch: 43 [(20%)]\tLoss: 0.226532\n",
            "Train epoch: 43 [(30%)]\tLoss: 0.371241\n",
            "Train epoch: 43 [(40%)]\tLoss: 0.344457\n",
            "Train epoch: 43 [(50%)]\tLoss: 0.297960\n",
            "Train epoch: 43 [(60%)]\tLoss: 0.599904\n",
            "Train epoch: 43 [(70%)]\tLoss: 0.279696\n",
            "Train epoch: 43 [(80%)]\tLoss: 0.211907\n",
            "Train epoch: 43 [(90%)]\tLoss: 0.218742\n",
            "Train epoch: 43 [(100%)]\tLoss: 0.180983\n",
            "Make prediction for 5010 samples...\n",
            "0.29312423 No improvement since epoch  41 ; best_mse,best_ci: 0.27766466 0.8791454786349749 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 44 [(0%)]\tLoss: 0.173513\n",
            "Train epoch: 44 [(10%)]\tLoss: 0.328130\n",
            "Train epoch: 44 [(20%)]\tLoss: 0.226419\n",
            "Train epoch: 44 [(30%)]\tLoss: 0.175723\n",
            "Train epoch: 44 [(40%)]\tLoss: 0.207714\n",
            "Train epoch: 44 [(50%)]\tLoss: 0.263313\n",
            "Train epoch: 44 [(60%)]\tLoss: 0.083785\n",
            "Train epoch: 44 [(70%)]\tLoss: 0.307227\n",
            "Train epoch: 44 [(80%)]\tLoss: 0.337631\n",
            "Train epoch: 44 [(90%)]\tLoss: 0.359108\n",
            "Train epoch: 44 [(100%)]\tLoss: 0.352811\n",
            "Make prediction for 5010 samples...\n",
            "0.31162435 No improvement since epoch  41 ; best_mse,best_ci: 0.27766466 0.8791454786349749 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 45 [(0%)]\tLoss: 0.141280\n",
            "Train epoch: 45 [(10%)]\tLoss: 0.255512\n",
            "Train epoch: 45 [(20%)]\tLoss: 0.069194\n",
            "Train epoch: 45 [(30%)]\tLoss: 0.203603\n",
            "Train epoch: 45 [(40%)]\tLoss: 0.232761\n",
            "Train epoch: 45 [(50%)]\tLoss: 0.226525\n",
            "Train epoch: 45 [(60%)]\tLoss: 0.269042\n",
            "Train epoch: 45 [(70%)]\tLoss: 0.169012\n",
            "Train epoch: 45 [(80%)]\tLoss: 0.229029\n",
            "Train epoch: 45 [(90%)]\tLoss: 0.339943\n",
            "Train epoch: 45 [(100%)]\tLoss: 0.117024\n",
            "Make prediction for 5010 samples...\n",
            "0.27880675 No improvement since epoch  41 ; best_mse,best_ci: 0.27766466 0.8791454786349749 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 46 [(0%)]\tLoss: 0.196267\n",
            "Train epoch: 46 [(10%)]\tLoss: 0.453314\n",
            "Train epoch: 46 [(20%)]\tLoss: 0.277907\n",
            "Train epoch: 46 [(30%)]\tLoss: 0.367719\n",
            "Train epoch: 46 [(40%)]\tLoss: 0.159088\n",
            "Train epoch: 46 [(50%)]\tLoss: 0.215622\n",
            "Train epoch: 46 [(60%)]\tLoss: 0.328662\n",
            "Train epoch: 46 [(70%)]\tLoss: 0.172073\n",
            "Train epoch: 46 [(80%)]\tLoss: 0.179852\n",
            "Train epoch: 46 [(90%)]\tLoss: 0.378781\n",
            "Train epoch: 46 [(100%)]\tLoss: 0.553286\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  46 ; best_mse,best_ci: 0.27545935 0.8799424084755905 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 47 [(0%)]\tLoss: 0.314982\n",
            "Train epoch: 47 [(10%)]\tLoss: 0.245792\n",
            "Train epoch: 47 [(20%)]\tLoss: 0.323711\n",
            "Train epoch: 47 [(30%)]\tLoss: 0.201060\n",
            "Train epoch: 47 [(40%)]\tLoss: 0.183025\n",
            "Train epoch: 47 [(50%)]\tLoss: 0.215366\n",
            "Train epoch: 47 [(60%)]\tLoss: 0.587554\n",
            "Train epoch: 47 [(70%)]\tLoss: 0.257153\n",
            "Train epoch: 47 [(80%)]\tLoss: 0.280285\n",
            "Train epoch: 47 [(90%)]\tLoss: 0.359069\n",
            "Train epoch: 47 [(100%)]\tLoss: 0.357581\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  47 ; best_mse,best_ci: 0.26759943 0.8821707030304162 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 48 [(0%)]\tLoss: 0.157398\n",
            "Train epoch: 48 [(10%)]\tLoss: 0.261482\n",
            "Train epoch: 48 [(20%)]\tLoss: 0.368787\n",
            "Train epoch: 48 [(30%)]\tLoss: 0.539667\n",
            "Train epoch: 48 [(40%)]\tLoss: 0.276637\n",
            "Train epoch: 48 [(50%)]\tLoss: 0.258021\n",
            "Train epoch: 48 [(60%)]\tLoss: 0.143926\n",
            "Train epoch: 48 [(70%)]\tLoss: 0.250694\n",
            "Train epoch: 48 [(80%)]\tLoss: 0.390198\n",
            "Train epoch: 48 [(90%)]\tLoss: 0.453101\n",
            "Train epoch: 48 [(100%)]\tLoss: 0.334801\n",
            "Make prediction for 5010 samples...\n",
            "0.26934862 No improvement since epoch  47 ; best_mse,best_ci: 0.26759943 0.8821707030304162 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 49 [(0%)]\tLoss: 0.229718\n",
            "Train epoch: 49 [(10%)]\tLoss: 0.213831\n",
            "Train epoch: 49 [(20%)]\tLoss: 0.116553\n",
            "Train epoch: 49 [(30%)]\tLoss: 0.278765\n",
            "Train epoch: 49 [(40%)]\tLoss: 0.310064\n",
            "Train epoch: 49 [(50%)]\tLoss: 0.391194\n",
            "Train epoch: 49 [(60%)]\tLoss: 0.399799\n",
            "Train epoch: 49 [(70%)]\tLoss: 0.241204\n",
            "Train epoch: 49 [(80%)]\tLoss: 0.186801\n",
            "Train epoch: 49 [(90%)]\tLoss: 0.258495\n",
            "Train epoch: 49 [(100%)]\tLoss: 0.282498\n",
            "Make prediction for 5010 samples...\n",
            "0.26856768 No improvement since epoch  47 ; best_mse,best_ci: 0.26759943 0.8821707030304162 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 50 [(0%)]\tLoss: 0.274739\n",
            "Train epoch: 50 [(10%)]\tLoss: 0.562677\n",
            "Train epoch: 50 [(20%)]\tLoss: 0.287220\n",
            "Train epoch: 50 [(30%)]\tLoss: 0.355941\n",
            "Train epoch: 50 [(40%)]\tLoss: 0.278261\n",
            "Train epoch: 50 [(50%)]\tLoss: 0.240126\n",
            "Train epoch: 50 [(60%)]\tLoss: 0.203316\n",
            "Train epoch: 50 [(70%)]\tLoss: 0.526163\n",
            "Train epoch: 50 [(80%)]\tLoss: 0.200005\n",
            "Train epoch: 50 [(90%)]\tLoss: 0.313061\n",
            "Train epoch: 50 [(100%)]\tLoss: 0.369445\n",
            "Make prediction for 5010 samples...\n",
            "0.27717134 No improvement since epoch  47 ; best_mse,best_ci: 0.26759943 0.8821707030304162 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 51 [(0%)]\tLoss: 0.168392\n",
            "Train epoch: 51 [(10%)]\tLoss: 0.344040\n",
            "Train epoch: 51 [(20%)]\tLoss: 0.338708\n",
            "Train epoch: 51 [(30%)]\tLoss: 0.510085\n",
            "Train epoch: 51 [(40%)]\tLoss: 0.090820\n",
            "Train epoch: 51 [(50%)]\tLoss: 0.386504\n",
            "Train epoch: 51 [(60%)]\tLoss: 0.203864\n",
            "Train epoch: 51 [(70%)]\tLoss: 0.252792\n",
            "Train epoch: 51 [(80%)]\tLoss: 0.239734\n",
            "Train epoch: 51 [(90%)]\tLoss: 0.198421\n",
            "Train epoch: 51 [(100%)]\tLoss: 0.221941\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  51 ; best_mse,best_ci: 0.26659697 0.878544048158546 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 52 [(0%)]\tLoss: 0.263773\n",
            "Train epoch: 52 [(10%)]\tLoss: 0.171399\n",
            "Train epoch: 52 [(20%)]\tLoss: 0.354228\n",
            "Train epoch: 52 [(30%)]\tLoss: 0.269859\n",
            "Train epoch: 52 [(40%)]\tLoss: 0.453651\n",
            "Train epoch: 52 [(50%)]\tLoss: 0.259154\n",
            "Train epoch: 52 [(60%)]\tLoss: 0.664813\n",
            "Train epoch: 52 [(70%)]\tLoss: 0.307724\n",
            "Train epoch: 52 [(80%)]\tLoss: 0.405463\n",
            "Train epoch: 52 [(90%)]\tLoss: 0.228971\n",
            "Train epoch: 52 [(100%)]\tLoss: 0.340380\n",
            "Make prediction for 5010 samples...\n",
            "0.30246276 No improvement since epoch  51 ; best_mse,best_ci: 0.26659697 0.878544048158546 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 53 [(0%)]\tLoss: 0.500194\n",
            "Train epoch: 53 [(10%)]\tLoss: 0.199001\n",
            "Train epoch: 53 [(20%)]\tLoss: 0.345964\n",
            "Train epoch: 53 [(30%)]\tLoss: 0.166035\n",
            "Train epoch: 53 [(40%)]\tLoss: 0.361659\n",
            "Train epoch: 53 [(50%)]\tLoss: 0.224772\n",
            "Train epoch: 53 [(60%)]\tLoss: 0.303514\n",
            "Train epoch: 53 [(70%)]\tLoss: 0.197280\n",
            "Train epoch: 53 [(80%)]\tLoss: 0.181784\n",
            "Train epoch: 53 [(90%)]\tLoss: 0.106255\n",
            "Train epoch: 53 [(100%)]\tLoss: 0.527687\n",
            "Make prediction for 5010 samples...\n",
            "0.27818266 No improvement since epoch  51 ; best_mse,best_ci: 0.26659697 0.878544048158546 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 54 [(0%)]\tLoss: 0.232573\n",
            "Train epoch: 54 [(10%)]\tLoss: 0.196177\n",
            "Train epoch: 54 [(20%)]\tLoss: 0.147501\n",
            "Train epoch: 54 [(30%)]\tLoss: 0.198402\n",
            "Train epoch: 54 [(40%)]\tLoss: 0.237074\n",
            "Train epoch: 54 [(50%)]\tLoss: 0.154541\n",
            "Train epoch: 54 [(60%)]\tLoss: 0.189348\n",
            "Train epoch: 54 [(70%)]\tLoss: 0.286844\n",
            "Train epoch: 54 [(80%)]\tLoss: 0.127884\n",
            "Train epoch: 54 [(90%)]\tLoss: 0.172118\n",
            "Train epoch: 54 [(100%)]\tLoss: 0.351000\n",
            "Make prediction for 5010 samples...\n",
            "0.2829688 No improvement since epoch  51 ; best_mse,best_ci: 0.26659697 0.878544048158546 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 55 [(0%)]\tLoss: 0.260093\n",
            "Train epoch: 55 [(10%)]\tLoss: 0.171482\n",
            "Train epoch: 55 [(20%)]\tLoss: 0.234551\n",
            "Train epoch: 55 [(30%)]\tLoss: 0.143493\n",
            "Train epoch: 55 [(40%)]\tLoss: 0.181164\n",
            "Train epoch: 55 [(50%)]\tLoss: 0.133608\n",
            "Train epoch: 55 [(60%)]\tLoss: 0.333496\n",
            "Train epoch: 55 [(70%)]\tLoss: 0.167138\n",
            "Train epoch: 55 [(80%)]\tLoss: 0.430980\n",
            "Train epoch: 55 [(90%)]\tLoss: 0.339947\n",
            "Train epoch: 55 [(100%)]\tLoss: 0.199119\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 56 [(0%)]\tLoss: 0.257102\n",
            "Train epoch: 56 [(10%)]\tLoss: 0.416016\n",
            "Train epoch: 56 [(20%)]\tLoss: 0.264787\n",
            "Train epoch: 56 [(30%)]\tLoss: 0.100658\n",
            "Train epoch: 56 [(40%)]\tLoss: 0.417853\n",
            "Train epoch: 56 [(50%)]\tLoss: 0.147949\n",
            "Train epoch: 56 [(60%)]\tLoss: 0.434922\n",
            "Train epoch: 56 [(70%)]\tLoss: 0.237363\n",
            "Train epoch: 56 [(80%)]\tLoss: 0.198678\n",
            "Train epoch: 56 [(90%)]\tLoss: 0.415394\n",
            "Train epoch: 56 [(100%)]\tLoss: 0.078977\n",
            "Make prediction for 5010 samples...\n",
            "0.262229 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 57 [(0%)]\tLoss: 0.160250\n",
            "Train epoch: 57 [(10%)]\tLoss: 0.094907\n",
            "Train epoch: 57 [(20%)]\tLoss: 0.217743\n",
            "Train epoch: 57 [(30%)]\tLoss: 0.161362\n",
            "Train epoch: 57 [(40%)]\tLoss: 0.208193\n",
            "Train epoch: 57 [(50%)]\tLoss: 0.205078\n",
            "Train epoch: 57 [(60%)]\tLoss: 0.246413\n",
            "Train epoch: 57 [(70%)]\tLoss: 0.111166\n",
            "Train epoch: 57 [(80%)]\tLoss: 0.171859\n",
            "Train epoch: 57 [(90%)]\tLoss: 0.233008\n",
            "Train epoch: 57 [(100%)]\tLoss: 0.178739\n",
            "Make prediction for 5010 samples...\n",
            "0.27906784 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 58 [(0%)]\tLoss: 0.194044\n",
            "Train epoch: 58 [(10%)]\tLoss: 0.320838\n",
            "Train epoch: 58 [(20%)]\tLoss: 0.274927\n",
            "Train epoch: 58 [(30%)]\tLoss: 0.087193\n",
            "Train epoch: 58 [(40%)]\tLoss: 0.252098\n",
            "Train epoch: 58 [(50%)]\tLoss: 0.178915\n",
            "Train epoch: 58 [(60%)]\tLoss: 0.193522\n",
            "Train epoch: 58 [(70%)]\tLoss: 0.345392\n",
            "Train epoch: 58 [(80%)]\tLoss: 0.224021\n",
            "Train epoch: 58 [(90%)]\tLoss: 0.337413\n",
            "Train epoch: 58 [(100%)]\tLoss: 0.230700\n",
            "Make prediction for 5010 samples...\n",
            "0.27942201 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 59 [(0%)]\tLoss: 0.303092\n",
            "Train epoch: 59 [(10%)]\tLoss: 0.351605\n",
            "Train epoch: 59 [(20%)]\tLoss: 0.168817\n",
            "Train epoch: 59 [(30%)]\tLoss: 0.342499\n",
            "Train epoch: 59 [(40%)]\tLoss: 0.184520\n",
            "Train epoch: 59 [(50%)]\tLoss: 0.189975\n",
            "Train epoch: 59 [(60%)]\tLoss: 0.316713\n",
            "Train epoch: 59 [(70%)]\tLoss: 0.121833\n",
            "Train epoch: 59 [(80%)]\tLoss: 0.216718\n",
            "Train epoch: 59 [(90%)]\tLoss: 0.237791\n",
            "Train epoch: 59 [(100%)]\tLoss: 0.143881\n",
            "Make prediction for 5010 samples...\n",
            "0.2713653 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 60 [(0%)]\tLoss: 0.252641\n",
            "Train epoch: 60 [(10%)]\tLoss: 0.253670\n",
            "Train epoch: 60 [(20%)]\tLoss: 0.415109\n",
            "Train epoch: 60 [(30%)]\tLoss: 0.224421\n",
            "Train epoch: 60 [(40%)]\tLoss: 0.377044\n",
            "Train epoch: 60 [(50%)]\tLoss: 0.437846\n",
            "Train epoch: 60 [(60%)]\tLoss: 0.175942\n",
            "Train epoch: 60 [(70%)]\tLoss: 0.184342\n",
            "Train epoch: 60 [(80%)]\tLoss: 0.075952\n",
            "Train epoch: 60 [(90%)]\tLoss: 0.223527\n",
            "Train epoch: 60 [(100%)]\tLoss: 0.202220\n",
            "Make prediction for 5010 samples...\n",
            "0.26140866 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 61 [(0%)]\tLoss: 0.088953\n",
            "Train epoch: 61 [(10%)]\tLoss: 0.265023\n",
            "Train epoch: 61 [(20%)]\tLoss: 0.484492\n",
            "Train epoch: 61 [(30%)]\tLoss: 0.177509\n",
            "Train epoch: 61 [(40%)]\tLoss: 0.524293\n",
            "Train epoch: 61 [(50%)]\tLoss: 0.307986\n",
            "Train epoch: 61 [(60%)]\tLoss: 0.215419\n",
            "Train epoch: 61 [(70%)]\tLoss: 0.295266\n",
            "Train epoch: 61 [(80%)]\tLoss: 0.220653\n",
            "Train epoch: 61 [(90%)]\tLoss: 0.246609\n",
            "Train epoch: 61 [(100%)]\tLoss: 0.270613\n",
            "Make prediction for 5010 samples...\n",
            "0.26508355 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 62 [(0%)]\tLoss: 0.105389\n",
            "Train epoch: 62 [(10%)]\tLoss: 0.115353\n",
            "Train epoch: 62 [(20%)]\tLoss: 0.091017\n",
            "Train epoch: 62 [(30%)]\tLoss: 0.210110\n",
            "Train epoch: 62 [(40%)]\tLoss: 0.149032\n",
            "Train epoch: 62 [(50%)]\tLoss: 0.185751\n",
            "Train epoch: 62 [(60%)]\tLoss: 0.142883\n",
            "Train epoch: 62 [(70%)]\tLoss: 0.292146\n",
            "Train epoch: 62 [(80%)]\tLoss: 0.212929\n",
            "Train epoch: 62 [(90%)]\tLoss: 0.207232\n",
            "Train epoch: 62 [(100%)]\tLoss: 0.207882\n",
            "Make prediction for 5010 samples...\n",
            "0.26434636 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 63 [(0%)]\tLoss: 0.140861\n",
            "Train epoch: 63 [(10%)]\tLoss: 0.407293\n",
            "Train epoch: 63 [(20%)]\tLoss: 0.215758\n",
            "Train epoch: 63 [(30%)]\tLoss: 0.343590\n",
            "Train epoch: 63 [(40%)]\tLoss: 0.197450\n",
            "Train epoch: 63 [(50%)]\tLoss: 0.283689\n",
            "Train epoch: 63 [(60%)]\tLoss: 0.108666\n",
            "Train epoch: 63 [(70%)]\tLoss: 0.104135\n",
            "Train epoch: 63 [(80%)]\tLoss: 0.308862\n",
            "Train epoch: 63 [(90%)]\tLoss: 0.238255\n",
            "Train epoch: 63 [(100%)]\tLoss: 0.249820\n",
            "Make prediction for 5010 samples...\n",
            "0.2579197 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 64 [(0%)]\tLoss: 0.232096\n",
            "Train epoch: 64 [(10%)]\tLoss: 0.365259\n",
            "Train epoch: 64 [(20%)]\tLoss: 0.323386\n",
            "Train epoch: 64 [(30%)]\tLoss: 0.201303\n",
            "Train epoch: 64 [(40%)]\tLoss: 0.210419\n",
            "Train epoch: 64 [(50%)]\tLoss: 0.214550\n",
            "Train epoch: 64 [(60%)]\tLoss: 0.088363\n",
            "Train epoch: 64 [(70%)]\tLoss: 0.205451\n",
            "Train epoch: 64 [(80%)]\tLoss: 0.230317\n",
            "Train epoch: 64 [(90%)]\tLoss: 0.364013\n",
            "Train epoch: 64 [(100%)]\tLoss: 0.394337\n",
            "Make prediction for 5010 samples...\n",
            "0.2675327 No improvement since epoch  55 ; best_mse,best_ci: 0.2543594 0.8863396714538613 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 65 [(0%)]\tLoss: 0.202380\n",
            "Train epoch: 65 [(10%)]\tLoss: 0.356002\n",
            "Train epoch: 65 [(20%)]\tLoss: 0.252388\n",
            "Train epoch: 65 [(30%)]\tLoss: 0.239826\n",
            "Train epoch: 65 [(40%)]\tLoss: 0.203397\n",
            "Train epoch: 65 [(50%)]\tLoss: 0.161681\n",
            "Train epoch: 65 [(60%)]\tLoss: 0.341114\n",
            "Train epoch: 65 [(70%)]\tLoss: 0.150969\n",
            "Train epoch: 65 [(80%)]\tLoss: 0.275680\n",
            "Train epoch: 65 [(90%)]\tLoss: 0.485150\n",
            "Train epoch: 65 [(100%)]\tLoss: 0.155065\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  65 ; best_mse,best_ci: 0.247547 0.8902362578802784 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 66 [(0%)]\tLoss: 0.531121\n",
            "Train epoch: 66 [(10%)]\tLoss: 0.133417\n",
            "Train epoch: 66 [(20%)]\tLoss: 0.155224\n",
            "Train epoch: 66 [(30%)]\tLoss: 0.112140\n",
            "Train epoch: 66 [(40%)]\tLoss: 0.141599\n",
            "Train epoch: 66 [(50%)]\tLoss: 0.160885\n",
            "Train epoch: 66 [(60%)]\tLoss: 0.130006\n",
            "Train epoch: 66 [(70%)]\tLoss: 0.109897\n",
            "Train epoch: 66 [(80%)]\tLoss: 0.239137\n",
            "Train epoch: 66 [(90%)]\tLoss: 0.249069\n",
            "Train epoch: 66 [(100%)]\tLoss: 0.178771\n",
            "Make prediction for 5010 samples...\n",
            "0.24968082 No improvement since epoch  65 ; best_mse,best_ci: 0.247547 0.8902362578802784 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 67 [(0%)]\tLoss: 0.139040\n",
            "Train epoch: 67 [(10%)]\tLoss: 0.145891\n",
            "Train epoch: 67 [(20%)]\tLoss: 0.276700\n",
            "Train epoch: 67 [(30%)]\tLoss: 0.232806\n",
            "Train epoch: 67 [(40%)]\tLoss: 0.104675\n",
            "Train epoch: 67 [(50%)]\tLoss: 0.331902\n",
            "Train epoch: 67 [(60%)]\tLoss: 0.249016\n",
            "Train epoch: 67 [(70%)]\tLoss: 0.131978\n",
            "Train epoch: 67 [(80%)]\tLoss: 0.114886\n",
            "Train epoch: 67 [(90%)]\tLoss: 0.363885\n",
            "Train epoch: 67 [(100%)]\tLoss: 0.099838\n",
            "Make prediction for 5010 samples...\n",
            "0.2524929 No improvement since epoch  65 ; best_mse,best_ci: 0.247547 0.8902362578802784 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 68 [(0%)]\tLoss: 0.182956\n",
            "Train epoch: 68 [(10%)]\tLoss: 0.124089\n",
            "Train epoch: 68 [(20%)]\tLoss: 0.327984\n",
            "Train epoch: 68 [(30%)]\tLoss: 0.151518\n",
            "Train epoch: 68 [(40%)]\tLoss: 0.128836\n",
            "Train epoch: 68 [(50%)]\tLoss: 0.232131\n",
            "Train epoch: 68 [(60%)]\tLoss: 0.342661\n",
            "Train epoch: 68 [(70%)]\tLoss: 0.138273\n",
            "Train epoch: 68 [(80%)]\tLoss: 0.448152\n",
            "Train epoch: 68 [(90%)]\tLoss: 0.195120\n",
            "Train epoch: 68 [(100%)]\tLoss: 0.240439\n",
            "Make prediction for 5010 samples...\n",
            "0.2574855 No improvement since epoch  65 ; best_mse,best_ci: 0.247547 0.8902362578802784 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 69 [(0%)]\tLoss: 0.459070\n",
            "Train epoch: 69 [(10%)]\tLoss: 0.099302\n",
            "Train epoch: 69 [(20%)]\tLoss: 0.177239\n",
            "Train epoch: 69 [(30%)]\tLoss: 0.186882\n",
            "Train epoch: 69 [(40%)]\tLoss: 0.253400\n",
            "Train epoch: 69 [(50%)]\tLoss: 0.169666\n",
            "Train epoch: 69 [(60%)]\tLoss: 0.171659\n",
            "Train epoch: 69 [(70%)]\tLoss: 0.147953\n",
            "Train epoch: 69 [(80%)]\tLoss: 0.170810\n",
            "Train epoch: 69 [(90%)]\tLoss: 0.202531\n",
            "Train epoch: 69 [(100%)]\tLoss: 0.225717\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 70 [(0%)]\tLoss: 0.150127\n",
            "Train epoch: 70 [(10%)]\tLoss: 0.208155\n",
            "Train epoch: 70 [(20%)]\tLoss: 0.069259\n",
            "Train epoch: 70 [(30%)]\tLoss: 0.400049\n",
            "Train epoch: 70 [(40%)]\tLoss: 0.125085\n",
            "Train epoch: 70 [(50%)]\tLoss: 0.203732\n",
            "Train epoch: 70 [(60%)]\tLoss: 0.087038\n",
            "Train epoch: 70 [(70%)]\tLoss: 0.251178\n",
            "Train epoch: 70 [(80%)]\tLoss: 0.150096\n",
            "Train epoch: 70 [(90%)]\tLoss: 0.230216\n",
            "Train epoch: 70 [(100%)]\tLoss: 0.115861\n",
            "Make prediction for 5010 samples...\n",
            "0.2538867 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 71 [(0%)]\tLoss: 0.085767\n",
            "Train epoch: 71 [(10%)]\tLoss: 0.117947\n",
            "Train epoch: 71 [(20%)]\tLoss: 0.272534\n",
            "Train epoch: 71 [(30%)]\tLoss: 0.176872\n",
            "Train epoch: 71 [(40%)]\tLoss: 0.178288\n",
            "Train epoch: 71 [(50%)]\tLoss: 0.218735\n",
            "Train epoch: 71 [(60%)]\tLoss: 0.156731\n",
            "Train epoch: 71 [(70%)]\tLoss: 0.140326\n",
            "Train epoch: 71 [(80%)]\tLoss: 0.098982\n",
            "Train epoch: 71 [(90%)]\tLoss: 0.208817\n",
            "Train epoch: 71 [(100%)]\tLoss: 0.111338\n",
            "Make prediction for 5010 samples...\n",
            "0.24546108 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 72 [(0%)]\tLoss: 0.458210\n",
            "Train epoch: 72 [(10%)]\tLoss: 0.105688\n",
            "Train epoch: 72 [(20%)]\tLoss: 0.137388\n",
            "Train epoch: 72 [(30%)]\tLoss: 0.270580\n",
            "Train epoch: 72 [(40%)]\tLoss: 0.235112\n",
            "Train epoch: 72 [(50%)]\tLoss: 0.221440\n",
            "Train epoch: 72 [(60%)]\tLoss: 0.167097\n",
            "Train epoch: 72 [(70%)]\tLoss: 0.104662\n",
            "Train epoch: 72 [(80%)]\tLoss: 0.240797\n",
            "Train epoch: 72 [(90%)]\tLoss: 0.230008\n",
            "Train epoch: 72 [(100%)]\tLoss: 0.336516\n",
            "Make prediction for 5010 samples...\n",
            "0.2639375 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 73 [(0%)]\tLoss: 0.457260\n",
            "Train epoch: 73 [(10%)]\tLoss: 0.118102\n",
            "Train epoch: 73 [(20%)]\tLoss: 0.217483\n",
            "Train epoch: 73 [(30%)]\tLoss: 0.297487\n",
            "Train epoch: 73 [(40%)]\tLoss: 0.317979\n",
            "Train epoch: 73 [(50%)]\tLoss: 0.362715\n",
            "Train epoch: 73 [(60%)]\tLoss: 0.125001\n",
            "Train epoch: 73 [(70%)]\tLoss: 0.231534\n",
            "Train epoch: 73 [(80%)]\tLoss: 0.176060\n",
            "Train epoch: 73 [(90%)]\tLoss: 0.218549\n",
            "Train epoch: 73 [(100%)]\tLoss: 0.114069\n",
            "Make prediction for 5010 samples...\n",
            "0.2551106 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 74 [(0%)]\tLoss: 0.156800\n",
            "Train epoch: 74 [(10%)]\tLoss: 0.125492\n",
            "Train epoch: 74 [(20%)]\tLoss: 0.201629\n",
            "Train epoch: 74 [(30%)]\tLoss: 0.245534\n",
            "Train epoch: 74 [(40%)]\tLoss: 0.124871\n",
            "Train epoch: 74 [(50%)]\tLoss: 0.219838\n",
            "Train epoch: 74 [(60%)]\tLoss: 0.157601\n",
            "Train epoch: 74 [(70%)]\tLoss: 0.178428\n",
            "Train epoch: 74 [(80%)]\tLoss: 0.160002\n",
            "Train epoch: 74 [(90%)]\tLoss: 0.144388\n",
            "Train epoch: 74 [(100%)]\tLoss: 0.164639\n",
            "Make prediction for 5010 samples...\n",
            "0.2492573 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 75 [(0%)]\tLoss: 0.381285\n",
            "Train epoch: 75 [(10%)]\tLoss: 0.121206\n",
            "Train epoch: 75 [(20%)]\tLoss: 0.097032\n",
            "Train epoch: 75 [(30%)]\tLoss: 0.210733\n",
            "Train epoch: 75 [(40%)]\tLoss: 0.242564\n",
            "Train epoch: 75 [(50%)]\tLoss: 0.096414\n",
            "Train epoch: 75 [(60%)]\tLoss: 0.067756\n",
            "Train epoch: 75 [(70%)]\tLoss: 0.093748\n",
            "Train epoch: 75 [(80%)]\tLoss: 0.256887\n",
            "Train epoch: 75 [(90%)]\tLoss: 0.098531\n",
            "Train epoch: 75 [(100%)]\tLoss: 0.276255\n",
            "Make prediction for 5010 samples...\n",
            "0.25082964 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 76 [(0%)]\tLoss: 0.173322\n",
            "Train epoch: 76 [(10%)]\tLoss: 0.164935\n",
            "Train epoch: 76 [(20%)]\tLoss: 0.522184\n",
            "Train epoch: 76 [(30%)]\tLoss: 0.077293\n",
            "Train epoch: 76 [(40%)]\tLoss: 0.113707\n",
            "Train epoch: 76 [(50%)]\tLoss: 0.142504\n",
            "Train epoch: 76 [(60%)]\tLoss: 0.178685\n",
            "Train epoch: 76 [(70%)]\tLoss: 0.163618\n",
            "Train epoch: 76 [(80%)]\tLoss: 0.183123\n",
            "Train epoch: 76 [(90%)]\tLoss: 0.175661\n",
            "Train epoch: 76 [(100%)]\tLoss: 0.173738\n",
            "Make prediction for 5010 samples...\n",
            "0.24743772 No improvement since epoch  69 ; best_mse,best_ci: 0.24510364 0.8890213744439984 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 77 [(0%)]\tLoss: 0.153564\n",
            "Train epoch: 77 [(10%)]\tLoss: 0.293294\n",
            "Train epoch: 77 [(20%)]\tLoss: 0.112344\n",
            "Train epoch: 77 [(30%)]\tLoss: 0.172812\n",
            "Train epoch: 77 [(40%)]\tLoss: 0.151749\n",
            "Train epoch: 77 [(50%)]\tLoss: 0.201956\n",
            "Train epoch: 77 [(60%)]\tLoss: 0.215233\n",
            "Train epoch: 77 [(70%)]\tLoss: 0.228626\n",
            "Train epoch: 77 [(80%)]\tLoss: 0.101040\n",
            "Train epoch: 77 [(90%)]\tLoss: 0.435247\n",
            "Train epoch: 77 [(100%)]\tLoss: 0.255888\n",
            "Make prediction for 5010 samples...\n",
            "rmse improved at epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 78 [(0%)]\tLoss: 0.173093\n",
            "Train epoch: 78 [(10%)]\tLoss: 0.094649\n",
            "Train epoch: 78 [(20%)]\tLoss: 0.095327\n",
            "Train epoch: 78 [(30%)]\tLoss: 0.229987\n",
            "Train epoch: 78 [(40%)]\tLoss: 0.168204\n",
            "Train epoch: 78 [(50%)]\tLoss: 0.220686\n",
            "Train epoch: 78 [(60%)]\tLoss: 0.307862\n",
            "Train epoch: 78 [(70%)]\tLoss: 0.192727\n",
            "Train epoch: 78 [(80%)]\tLoss: 0.224006\n",
            "Train epoch: 78 [(90%)]\tLoss: 0.123726\n",
            "Train epoch: 78 [(100%)]\tLoss: 0.102910\n",
            "Make prediction for 5010 samples...\n",
            "0.24639581 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 79 [(0%)]\tLoss: 0.084604\n",
            "Train epoch: 79 [(10%)]\tLoss: 0.284022\n",
            "Train epoch: 79 [(20%)]\tLoss: 0.336290\n",
            "Train epoch: 79 [(30%)]\tLoss: 0.144841\n",
            "Train epoch: 79 [(40%)]\tLoss: 0.224541\n",
            "Train epoch: 79 [(50%)]\tLoss: 0.151185\n",
            "Train epoch: 79 [(60%)]\tLoss: 0.297354\n",
            "Train epoch: 79 [(70%)]\tLoss: 0.166177\n",
            "Train epoch: 79 [(80%)]\tLoss: 0.151002\n",
            "Train epoch: 79 [(90%)]\tLoss: 0.224357\n",
            "Train epoch: 79 [(100%)]\tLoss: 0.101161\n",
            "Make prediction for 5010 samples...\n",
            "0.2474241 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 80 [(0%)]\tLoss: 0.119195\n",
            "Train epoch: 80 [(10%)]\tLoss: 0.122748\n",
            "Train epoch: 80 [(20%)]\tLoss: 0.099169\n",
            "Train epoch: 80 [(30%)]\tLoss: 0.058686\n",
            "Train epoch: 80 [(40%)]\tLoss: 0.405567\n",
            "Train epoch: 80 [(50%)]\tLoss: 0.118672\n",
            "Train epoch: 80 [(60%)]\tLoss: 0.283526\n",
            "Train epoch: 80 [(70%)]\tLoss: 0.237116\n",
            "Train epoch: 80 [(80%)]\tLoss: 0.093604\n",
            "Train epoch: 80 [(90%)]\tLoss: 0.078900\n",
            "Train epoch: 80 [(100%)]\tLoss: 0.303213\n",
            "Make prediction for 5010 samples...\n",
            "0.24174456 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 81 [(0%)]\tLoss: 0.138443\n",
            "Train epoch: 81 [(10%)]\tLoss: 0.266399\n",
            "Train epoch: 81 [(20%)]\tLoss: 0.131917\n",
            "Train epoch: 81 [(30%)]\tLoss: 0.102897\n",
            "Train epoch: 81 [(40%)]\tLoss: 0.149382\n",
            "Train epoch: 81 [(50%)]\tLoss: 0.345384\n",
            "Train epoch: 81 [(60%)]\tLoss: 0.154651\n",
            "Train epoch: 81 [(70%)]\tLoss: 0.117715\n",
            "Train epoch: 81 [(80%)]\tLoss: 0.188089\n",
            "Train epoch: 81 [(90%)]\tLoss: 0.203088\n",
            "Train epoch: 81 [(100%)]\tLoss: 0.135516\n",
            "Make prediction for 5010 samples...\n",
            "0.24808924 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 82 [(0%)]\tLoss: 0.110489\n",
            "Train epoch: 82 [(10%)]\tLoss: 0.121435\n",
            "Train epoch: 82 [(20%)]\tLoss: 0.237034\n",
            "Train epoch: 82 [(30%)]\tLoss: 0.238353\n",
            "Train epoch: 82 [(40%)]\tLoss: 0.409177\n",
            "Train epoch: 82 [(50%)]\tLoss: 0.121371\n",
            "Train epoch: 82 [(60%)]\tLoss: 0.151978\n",
            "Train epoch: 82 [(70%)]\tLoss: 0.242847\n",
            "Train epoch: 82 [(80%)]\tLoss: 0.223912\n",
            "Train epoch: 82 [(90%)]\tLoss: 0.380142\n",
            "Train epoch: 82 [(100%)]\tLoss: 0.294536\n",
            "Make prediction for 5010 samples...\n",
            "0.24203892 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 83 [(0%)]\tLoss: 0.268720\n",
            "Train epoch: 83 [(10%)]\tLoss: 0.239444\n",
            "Train epoch: 83 [(20%)]\tLoss: 0.052336\n",
            "Train epoch: 83 [(30%)]\tLoss: 0.229840\n",
            "Train epoch: 83 [(40%)]\tLoss: 0.191394\n",
            "Train epoch: 83 [(50%)]\tLoss: 0.172706\n",
            "Train epoch: 83 [(60%)]\tLoss: 0.088401\n",
            "Train epoch: 83 [(70%)]\tLoss: 0.228913\n",
            "Train epoch: 83 [(80%)]\tLoss: 0.172944\n",
            "Train epoch: 83 [(90%)]\tLoss: 0.199741\n",
            "Train epoch: 83 [(100%)]\tLoss: 0.178146\n",
            "Make prediction for 5010 samples...\n",
            "0.25741208 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 84 [(0%)]\tLoss: 0.148626\n",
            "Train epoch: 84 [(10%)]\tLoss: 0.180954\n",
            "Train epoch: 84 [(20%)]\tLoss: 0.094240\n",
            "Train epoch: 84 [(30%)]\tLoss: 0.184963\n",
            "Train epoch: 84 [(40%)]\tLoss: 0.095523\n",
            "Train epoch: 84 [(50%)]\tLoss: 0.153007\n",
            "Train epoch: 84 [(60%)]\tLoss: 0.261969\n",
            "Train epoch: 84 [(70%)]\tLoss: 0.255507\n",
            "Train epoch: 84 [(80%)]\tLoss: 0.161233\n",
            "Train epoch: 84 [(90%)]\tLoss: 0.295431\n",
            "Train epoch: 84 [(100%)]\tLoss: 0.258928\n",
            "Make prediction for 5010 samples...\n",
            "0.24876702 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 85 [(0%)]\tLoss: 0.169671\n",
            "Train epoch: 85 [(10%)]\tLoss: 0.145734\n",
            "Train epoch: 85 [(20%)]\tLoss: 0.152576\n",
            "Train epoch: 85 [(30%)]\tLoss: 0.142480\n",
            "Train epoch: 85 [(40%)]\tLoss: 0.153415\n",
            "Train epoch: 85 [(50%)]\tLoss: 0.147638\n",
            "Train epoch: 85 [(60%)]\tLoss: 0.085504\n",
            "Train epoch: 85 [(70%)]\tLoss: 0.166394\n",
            "Train epoch: 85 [(80%)]\tLoss: 0.125246\n",
            "Train epoch: 85 [(90%)]\tLoss: 0.193687\n",
            "Train epoch: 85 [(100%)]\tLoss: 0.145092\n",
            "Make prediction for 5010 samples...\n",
            "0.254609 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 86 [(0%)]\tLoss: 0.201609\n",
            "Train epoch: 86 [(10%)]\tLoss: 0.116087\n",
            "Train epoch: 86 [(20%)]\tLoss: 0.141680\n",
            "Train epoch: 86 [(30%)]\tLoss: 0.188824\n",
            "Train epoch: 86 [(40%)]\tLoss: 0.151433\n",
            "Train epoch: 86 [(50%)]\tLoss: 0.121444\n",
            "Train epoch: 86 [(60%)]\tLoss: 0.126925\n",
            "Train epoch: 86 [(70%)]\tLoss: 0.154928\n",
            "Train epoch: 86 [(80%)]\tLoss: 0.269287\n",
            "Train epoch: 86 [(90%)]\tLoss: 0.193250\n",
            "Train epoch: 86 [(100%)]\tLoss: 0.087695\n",
            "Make prediction for 5010 samples...\n",
            "0.24098186 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 87 [(0%)]\tLoss: 0.168563\n",
            "Train epoch: 87 [(10%)]\tLoss: 0.130442\n",
            "Train epoch: 87 [(20%)]\tLoss: 0.095666\n",
            "Train epoch: 87 [(30%)]\tLoss: 0.348705\n",
            "Train epoch: 87 [(40%)]\tLoss: 0.171767\n",
            "Train epoch: 87 [(50%)]\tLoss: 0.121965\n",
            "Train epoch: 87 [(60%)]\tLoss: 0.438106\n",
            "Train epoch: 87 [(70%)]\tLoss: 0.235580\n",
            "Train epoch: 87 [(80%)]\tLoss: 0.240464\n",
            "Train epoch: 87 [(90%)]\tLoss: 0.153694\n",
            "Train epoch: 87 [(100%)]\tLoss: 0.238193\n",
            "Make prediction for 5010 samples...\n",
            "0.27485168 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 88 [(0%)]\tLoss: 0.323839\n",
            "Train epoch: 88 [(10%)]\tLoss: 0.224822\n",
            "Train epoch: 88 [(20%)]\tLoss: 0.282250\n",
            "Train epoch: 88 [(30%)]\tLoss: 0.243383\n",
            "Train epoch: 88 [(40%)]\tLoss: 0.483422\n",
            "Train epoch: 88 [(50%)]\tLoss: 0.472093\n",
            "Train epoch: 88 [(60%)]\tLoss: 0.309380\n",
            "Train epoch: 88 [(70%)]\tLoss: 0.254155\n",
            "Train epoch: 88 [(80%)]\tLoss: 0.422674\n",
            "Train epoch: 88 [(90%)]\tLoss: 0.133678\n",
            "Train epoch: 88 [(100%)]\tLoss: 0.274637\n",
            "Make prediction for 5010 samples...\n",
            "0.2723247 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 89 [(0%)]\tLoss: 0.242304\n",
            "Train epoch: 89 [(10%)]\tLoss: 0.191054\n",
            "Train epoch: 89 [(20%)]\tLoss: 0.366861\n",
            "Train epoch: 89 [(30%)]\tLoss: 0.284618\n",
            "Train epoch: 89 [(40%)]\tLoss: 0.337954\n",
            "Train epoch: 89 [(50%)]\tLoss: 0.503538\n",
            "Train epoch: 89 [(60%)]\tLoss: 0.183871\n",
            "Train epoch: 89 [(70%)]\tLoss: 0.234965\n",
            "Train epoch: 89 [(80%)]\tLoss: 0.139572\n",
            "Train epoch: 89 [(90%)]\tLoss: 0.350499\n",
            "Train epoch: 89 [(100%)]\tLoss: 0.060463\n",
            "Make prediction for 5010 samples...\n",
            "0.2669818 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 90 [(0%)]\tLoss: 0.440065\n",
            "Train epoch: 90 [(10%)]\tLoss: 0.219874\n",
            "Train epoch: 90 [(20%)]\tLoss: 0.172169\n",
            "Train epoch: 90 [(30%)]\tLoss: 0.208812\n",
            "Train epoch: 90 [(40%)]\tLoss: 0.112907\n",
            "Train epoch: 90 [(50%)]\tLoss: 0.290129\n",
            "Train epoch: 90 [(60%)]\tLoss: 0.103652\n",
            "Train epoch: 90 [(70%)]\tLoss: 0.118530\n",
            "Train epoch: 90 [(80%)]\tLoss: 0.210540\n",
            "Train epoch: 90 [(90%)]\tLoss: 0.197939\n",
            "Train epoch: 90 [(100%)]\tLoss: 0.195820\n",
            "Make prediction for 5010 samples...\n",
            "0.26031888 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 91 [(0%)]\tLoss: 0.139489\n",
            "Train epoch: 91 [(10%)]\tLoss: 0.214858\n",
            "Train epoch: 91 [(20%)]\tLoss: 0.194384\n",
            "Train epoch: 91 [(30%)]\tLoss: 0.306166\n",
            "Train epoch: 91 [(40%)]\tLoss: 0.202106\n",
            "Train epoch: 91 [(50%)]\tLoss: 0.326441\n",
            "Train epoch: 91 [(60%)]\tLoss: 0.291586\n",
            "Train epoch: 91 [(70%)]\tLoss: 0.208957\n",
            "Train epoch: 91 [(80%)]\tLoss: 0.580561\n",
            "Train epoch: 91 [(90%)]\tLoss: 0.362794\n",
            "Train epoch: 91 [(100%)]\tLoss: 0.155496\n",
            "Make prediction for 5010 samples...\n",
            "0.25379324 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 92 [(0%)]\tLoss: 0.119383\n",
            "Train epoch: 92 [(10%)]\tLoss: 0.152334\n",
            "Train epoch: 92 [(20%)]\tLoss: 0.228198\n",
            "Train epoch: 92 [(30%)]\tLoss: 0.180624\n",
            "Train epoch: 92 [(40%)]\tLoss: 0.287299\n",
            "Train epoch: 92 [(50%)]\tLoss: 0.198129\n",
            "Train epoch: 92 [(60%)]\tLoss: 0.223401\n",
            "Train epoch: 92 [(70%)]\tLoss: 0.197859\n",
            "Train epoch: 92 [(80%)]\tLoss: 0.236947\n",
            "Train epoch: 92 [(90%)]\tLoss: 0.127462\n",
            "Train epoch: 92 [(100%)]\tLoss: 0.352919\n",
            "Make prediction for 5010 samples...\n",
            "0.2476754 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 93 [(0%)]\tLoss: 0.249653\n",
            "Train epoch: 93 [(10%)]\tLoss: 0.220681\n",
            "Train epoch: 93 [(20%)]\tLoss: 0.238584\n",
            "Train epoch: 93 [(30%)]\tLoss: 0.331222\n",
            "Train epoch: 93 [(40%)]\tLoss: 0.731180\n",
            "Train epoch: 93 [(50%)]\tLoss: 0.418107\n",
            "Train epoch: 93 [(60%)]\tLoss: 0.334549\n",
            "Train epoch: 93 [(70%)]\tLoss: 0.340373\n",
            "Train epoch: 93 [(80%)]\tLoss: 0.293102\n",
            "Train epoch: 93 [(90%)]\tLoss: 0.227904\n",
            "Train epoch: 93 [(100%)]\tLoss: 0.366531\n",
            "Make prediction for 5010 samples...\n",
            "0.33301064 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 94 [(0%)]\tLoss: 0.197481\n",
            "Train epoch: 94 [(10%)]\tLoss: 0.340143\n",
            "Train epoch: 94 [(20%)]\tLoss: 0.218428\n",
            "Train epoch: 94 [(30%)]\tLoss: 0.522187\n",
            "Train epoch: 94 [(40%)]\tLoss: 0.255821\n",
            "Train epoch: 94 [(50%)]\tLoss: 0.256640\n",
            "Train epoch: 94 [(60%)]\tLoss: 0.391080\n",
            "Train epoch: 94 [(70%)]\tLoss: 0.496542\n",
            "Train epoch: 94 [(80%)]\tLoss: 0.353311\n",
            "Train epoch: 94 [(90%)]\tLoss: 0.273037\n",
            "Train epoch: 94 [(100%)]\tLoss: 0.246048\n",
            "Make prediction for 5010 samples...\n",
            "0.30871037 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 95 [(0%)]\tLoss: 0.308020\n",
            "Train epoch: 95 [(10%)]\tLoss: 0.230744\n",
            "Train epoch: 95 [(20%)]\tLoss: 0.753646\n",
            "Train epoch: 95 [(30%)]\tLoss: 0.225261\n",
            "Train epoch: 95 [(40%)]\tLoss: 0.249983\n",
            "Train epoch: 95 [(50%)]\tLoss: 0.109702\n",
            "Train epoch: 95 [(60%)]\tLoss: 0.318929\n",
            "Train epoch: 95 [(70%)]\tLoss: 0.175575\n",
            "Train epoch: 95 [(80%)]\tLoss: 0.191321\n",
            "Train epoch: 95 [(90%)]\tLoss: 0.457233\n",
            "Train epoch: 95 [(100%)]\tLoss: 0.295018\n",
            "Make prediction for 5010 samples...\n",
            "0.27466458 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 96 [(0%)]\tLoss: 0.221369\n",
            "Train epoch: 96 [(10%)]\tLoss: 0.373764\n",
            "Train epoch: 96 [(20%)]\tLoss: 0.459947\n",
            "Train epoch: 96 [(30%)]\tLoss: 0.144421\n",
            "Train epoch: 96 [(40%)]\tLoss: 0.477455\n",
            "Train epoch: 96 [(50%)]\tLoss: 0.357772\n",
            "Train epoch: 96 [(60%)]\tLoss: 0.498063\n",
            "Train epoch: 96 [(70%)]\tLoss: 0.851718\n",
            "Train epoch: 96 [(80%)]\tLoss: 0.788124\n",
            "Train epoch: 96 [(90%)]\tLoss: 0.738542\n",
            "Train epoch: 96 [(100%)]\tLoss: 0.384677\n",
            "Make prediction for 5010 samples...\n",
            "0.8872976 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 97 [(0%)]\tLoss: 0.449999\n",
            "Train epoch: 97 [(10%)]\tLoss: 0.823062\n",
            "Train epoch: 97 [(20%)]\tLoss: 0.583388\n",
            "Train epoch: 97 [(30%)]\tLoss: 0.579088\n",
            "Train epoch: 97 [(40%)]\tLoss: 0.663275\n",
            "Train epoch: 97 [(50%)]\tLoss: 0.424677\n",
            "Train epoch: 97 [(60%)]\tLoss: 0.537641\n",
            "Train epoch: 97 [(70%)]\tLoss: 0.336153\n",
            "Train epoch: 97 [(80%)]\tLoss: 0.555601\n",
            "Train epoch: 97 [(90%)]\tLoss: 0.382648\n",
            "Train epoch: 97 [(100%)]\tLoss: 0.389229\n",
            "Make prediction for 5010 samples...\n",
            "0.5893181 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 98 [(0%)]\tLoss: 0.935855\n",
            "Train epoch: 98 [(10%)]\tLoss: 0.586605\n",
            "Train epoch: 98 [(20%)]\tLoss: 0.561604\n",
            "Train epoch: 98 [(30%)]\tLoss: 0.913049\n",
            "Train epoch: 98 [(40%)]\tLoss: 0.337698\n",
            "Train epoch: 98 [(50%)]\tLoss: 0.325134\n",
            "Train epoch: 98 [(60%)]\tLoss: 1.052886\n",
            "Train epoch: 98 [(70%)]\tLoss: 0.619457\n",
            "Train epoch: 98 [(80%)]\tLoss: 0.700880\n",
            "Train epoch: 98 [(90%)]\tLoss: 0.568071\n",
            "Train epoch: 98 [(100%)]\tLoss: 0.483811\n",
            "Make prediction for 5010 samples...\n",
            "0.47510028 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 99 [(0%)]\tLoss: 0.465815\n",
            "Train epoch: 99 [(10%)]\tLoss: 0.622231\n",
            "Train epoch: 99 [(20%)]\tLoss: 0.370395\n",
            "Train epoch: 99 [(30%)]\tLoss: 0.485168\n",
            "Train epoch: 99 [(40%)]\tLoss: 0.326938\n",
            "Train epoch: 99 [(50%)]\tLoss: 0.323902\n",
            "Train epoch: 99 [(60%)]\tLoss: 0.687140\n",
            "Train epoch: 99 [(70%)]\tLoss: 0.585139\n",
            "Train epoch: 99 [(80%)]\tLoss: 0.501404\n",
            "Train epoch: 99 [(90%)]\tLoss: 0.569289\n",
            "Train epoch: 99 [(100%)]\tLoss: 0.333003\n",
            "Make prediction for 5010 samples...\n",
            "0.43298393 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n",
            "Training on 25046 samples...\n",
            "Train epoch: 100 [(0%)]\tLoss: 0.319857\n",
            "Train epoch: 100 [(10%)]\tLoss: 0.636808\n",
            "Train epoch: 100 [(20%)]\tLoss: 0.622355\n",
            "Train epoch: 100 [(30%)]\tLoss: 0.505175\n",
            "Train epoch: 100 [(40%)]\tLoss: 0.436897\n",
            "Train epoch: 100 [(50%)]\tLoss: 0.253451\n",
            "Train epoch: 100 [(60%)]\tLoss: 0.555028\n",
            "Train epoch: 100 [(70%)]\tLoss: 0.261099\n",
            "Train epoch: 100 [(80%)]\tLoss: 0.372714\n",
            "Train epoch: 100 [(90%)]\tLoss: 0.506922\n",
            "Train epoch: 100 [(100%)]\tLoss: 0.366725\n",
            "Make prediction for 5010 samples...\n",
            "0.4005996 No improvement since epoch  77 ; best_mse,best_ci: 0.23939894 0.8934095808931648 att_GAT davis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEbnLrS3z6z9"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}